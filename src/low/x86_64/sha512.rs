//! Copyright (c) 2006, CRYPTOGAMS by <appro@openssl.org> All rights reserved.
//! SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0-only
//!
//! ====================================================================
//! Written by Andy Polyakov, @dot-asm, initially for the OpenSSL
//! project.
//! ====================================================================
//!
//! sha256/512_block procedure for x86_64.
//!
//! 40% improvement over compiler-generated code on Opteron. On EM64T
//! sha256 was observed to run >80% faster and sha512 - >40%. No magical
//! tricks, just straight implementation... I really wonder why gcc
//! [being armed with inline assembler] fails to generate as fast code.
//! The only thing which is cool about this module is that it's very
//! same instruction sequence used for both SHA-256 and SHA-512. In
//! former case the instructions operate on 32-bit operands, while in
//! latter - on 64-bit ones. All I had to do is to get one flavor right,
//! the other one passed the test right away:-)
//!
//! sha256_block runs in ~1005 cycles on Opteron, which gives you
//! asymptotic performance of 64*1000/1005=63.7MBps times CPU clock
//! frequency in GHz. sha512_block runs in ~1275 cycles, which results
//! in 128*1000/1275=100MBps per GHz. Is there room for improvement?
//! Well, if you compare it to IA-64 implementation, which maintains
//! X[16] in register bank[!], tends to 4 instructions per CPU clock
//! cycle and runs in 1003 cycles, 1275 is very good result for 3-way
//! issue Opteron pipeline and X[16] maintained in memory. So that *if*
//! there is a way to improve it, *then* the only way would be to try to
//! offload X[16] updates to SSE unit, but that would require "deeper"
//! loop unroll, which in turn would naturally cause size blow-up, not
//! to mention increased complexity! And once again, only *if* it's
//! actually possible to noticeably improve overall ILP, instruction
//! level parallelism, on a given CPU implementation in this case.
//!
//! Special note on Intel EM64T. While Opteron CPU exhibits perfect
//! performance ratio of 1.5 between 64- and 32-bit flavors [see above],
//! [currently available] EM64T CPUs apparently are far from it. On the
//! contrary, 64-bit version, sha512_block, is ~30% *slower* than 32-bit
//! sha256_block:-( This is presumably because 64-bit shifts/rotates
//! apparently are not atomic instructions, but implemented in microcode.
//!
//! May 2012.
//!
//! Optimization including one of Pavel Semjanov's ideas, alternative
//! Maj, resulted in >=5% improvement on most CPUs, +20% SHA256 and
//! unfortunately -2% SHA512 on P4 [which nobody should care about
//! that much].
//!
//! June 2012.
//!
//! Add SIMD code paths, see below for improvement coefficients. SSSE3
//! code path was not attempted for SHA512, because improvement is not
//! estimated to be high enough, noticeably less than 9%, to justify
//! the effort, not on pre-AVX processors. [Obviously with exclusion
//! for VIA Nano, but it has SHA512 instruction that is faster and
//! should be used instead.] For reference, corresponding estimated
//! upper limit for improvement for SSSE3 SHA256 is 28%. The fact that
//! higher coefficients are observed on VIA Nano and Bulldozer has more
//! to do with specifics of their architecture [which is topic for
//! separate discussion].
//!
//! November 2012.
//!
//! Add AVX2 code path. Two consecutive input blocks are loaded to
//! 256-bit %ymm registers, with data from first block to least
//! significant 128-bit halves and data from second to most significant.
//! The data is then processed with same SIMD instruction sequence as
//! for AVX, but with %ymm as operands. Side effect is increased stack
//! frame, 448 additional bytes in SHA256 and 1152 in SHA512, and 1.2KB
//! code size increase.
//!
//! March 2014.
//!
//! Add support for Intel SHA Extensions.
//!
//! October 2023.
//!
//! Add support for Intel SHA512 Extension.

#![allow(non_upper_case_globals, unused_macros, unused_imports)]
use crate::low::macros::{Label, Q};

#[allow(dead_code)]
#[repr(align(64))]
struct B64Alignedu64Array164([u64; 164]);

static K512: B64Alignedu64Array164 = B64Alignedu64Array164([
    0x428a2f98d728ae22,
    0x7137449123ef65cd,
    0x428a2f98d728ae22,
    0x7137449123ef65cd,
    0xb5c0fbcfec4d3b2f,
    0xe9b5dba58189dbbc,
    0xb5c0fbcfec4d3b2f,
    0xe9b5dba58189dbbc,
    0x3956c25bf348b538,
    0x59f111f1b605d019,
    0x3956c25bf348b538,
    0x59f111f1b605d019,
    0x923f82a4af194f9b,
    0xab1c5ed5da6d8118,
    0x923f82a4af194f9b,
    0xab1c5ed5da6d8118,
    0xd807aa98a3030242,
    0x12835b0145706fbe,
    0xd807aa98a3030242,
    0x12835b0145706fbe,
    0x243185be4ee4b28c,
    0x550c7dc3d5ffb4e2,
    0x243185be4ee4b28c,
    0x550c7dc3d5ffb4e2,
    0x72be5d74f27b896f,
    0x80deb1fe3b1696b1,
    0x72be5d74f27b896f,
    0x80deb1fe3b1696b1,
    0x9bdc06a725c71235,
    0xc19bf174cf692694,
    0x9bdc06a725c71235,
    0xc19bf174cf692694,
    0xe49b69c19ef14ad2,
    0xefbe4786384f25e3,
    0xe49b69c19ef14ad2,
    0xefbe4786384f25e3,
    0x0fc19dc68b8cd5b5,
    0x240ca1cc77ac9c65,
    0x0fc19dc68b8cd5b5,
    0x240ca1cc77ac9c65,
    0x2de92c6f592b0275,
    0x4a7484aa6ea6e483,
    0x2de92c6f592b0275,
    0x4a7484aa6ea6e483,
    0x5cb0a9dcbd41fbd4,
    0x76f988da831153b5,
    0x5cb0a9dcbd41fbd4,
    0x76f988da831153b5,
    0x983e5152ee66dfab,
    0xa831c66d2db43210,
    0x983e5152ee66dfab,
    0xa831c66d2db43210,
    0xb00327c898fb213f,
    0xbf597fc7beef0ee4,
    0xb00327c898fb213f,
    0xbf597fc7beef0ee4,
    0xc6e00bf33da88fc2,
    0xd5a79147930aa725,
    0xc6e00bf33da88fc2,
    0xd5a79147930aa725,
    0x06ca6351e003826f,
    0x142929670a0e6e70,
    0x06ca6351e003826f,
    0x142929670a0e6e70,
    0x27b70a8546d22ffc,
    0x2e1b21385c26c926,
    0x27b70a8546d22ffc,
    0x2e1b21385c26c926,
    0x4d2c6dfc5ac42aed,
    0x53380d139d95b3df,
    0x4d2c6dfc5ac42aed,
    0x53380d139d95b3df,
    0x650a73548baf63de,
    0x766a0abb3c77b2a8,
    0x650a73548baf63de,
    0x766a0abb3c77b2a8,
    0x81c2c92e47edaee6,
    0x92722c851482353b,
    0x81c2c92e47edaee6,
    0x92722c851482353b,
    0xa2bfe8a14cf10364,
    0xa81a664bbc423001,
    0xa2bfe8a14cf10364,
    0xa81a664bbc423001,
    0xc24b8b70d0f89791,
    0xc76c51a30654be30,
    0xc24b8b70d0f89791,
    0xc76c51a30654be30,
    0xd192e819d6ef5218,
    0xd69906245565a910,
    0xd192e819d6ef5218,
    0xd69906245565a910,
    0xf40e35855771202a,
    0x106aa07032bbd1b8,
    0xf40e35855771202a,
    0x106aa07032bbd1b8,
    0x19a4c116b8d2d0c8,
    0x1e376c085141ab53,
    0x19a4c116b8d2d0c8,
    0x1e376c085141ab53,
    0x2748774cdf8eeb99,
    0x34b0bcb5e19b48a8,
    0x2748774cdf8eeb99,
    0x34b0bcb5e19b48a8,
    0x391c0cb3c5c95a63,
    0x4ed8aa4ae3418acb,
    0x391c0cb3c5c95a63,
    0x4ed8aa4ae3418acb,
    0x5b9cca4f7763e373,
    0x682e6ff3d6b2b8a3,
    0x5b9cca4f7763e373,
    0x682e6ff3d6b2b8a3,
    0x748f82ee5defb2fc,
    0x78a5636f43172f60,
    0x748f82ee5defb2fc,
    0x78a5636f43172f60,
    0x84c87814a1f0ab72,
    0x8cc702081a6439ec,
    0x84c87814a1f0ab72,
    0x8cc702081a6439ec,
    0x90befffa23631e28,
    0xa4506cebde82bde9,
    0x90befffa23631e28,
    0xa4506cebde82bde9,
    0xbef9a3f7b2c67915,
    0xc67178f2e372532b,
    0xbef9a3f7b2c67915,
    0xc67178f2e372532b,
    0xca273eceea26619c,
    0xd186b8c721c0c207,
    0xca273eceea26619c,
    0xd186b8c721c0c207,
    0xeada7dd6cde0eb1e,
    0xf57d4f7fee6ed178,
    0xeada7dd6cde0eb1e,
    0xf57d4f7fee6ed178,
    0x06f067aa72176fba,
    0x0a637dc5a2c898a6,
    0x06f067aa72176fba,
    0x0a637dc5a2c898a6,
    0x113f9804bef90dae,
    0x1b710b35131c471b,
    0x113f9804bef90dae,
    0x1b710b35131c471b,
    0x28db77f523047d84,
    0x32caab7b40c72493,
    0x28db77f523047d84,
    0x32caab7b40c72493,
    0x3c9ebe0a15c9bebc,
    0x431d67c49c100d4c,
    0x3c9ebe0a15c9bebc,
    0x431d67c49c100d4c,
    0x4cc5d4becb3e42b6,
    0x597f299cfc657e2a,
    0x4cc5d4becb3e42b6,
    0x597f299cfc657e2a,
    0x5fcb6fab3ad6faec,
    0x6c44198c4a475817,
    0x5fcb6fab3ad6faec,
    0x6c44198c4a475817,
    0x0001020304050607,
    0x08090a0b0c0d0e0f,
    0x0001020304050607,
    0x08090a0b0c0d0e0f,
]);

#[inline(never)]
pub fn sha512_block_data_order_avx(state: &mut [u64; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lavx_shortcut", 2) ":"),
        Q!("    pushq           " "%rbx"),
        Q!("    pushq           " "%r12"),
        Q!("    pushq           " "%r13"),
        Q!("    pushq           " "%r14"),
        Q!("    pushq           " "%r15"),
        Q!("    shlq            " "$4, %rdx"),
        Q!("    subq            " "$24, %rsp"),
        Q!("    leaq            " "(%rsi, %rdx, 8), %rdx"),
        Q!("    movq            " "%rdi, -64 (%rbp)"),
        Q!("    movq            " "%rdx, -48 (%rbp)"),
        Q!("    leaq            " "-128 (%rsp), %rsp"),
        Q!("    vzeroupper      " ),
        Q!("    andq            " "$-64, %rsp"),
        Q!("    movq            " "0 (%rdi), %rax"),
        Q!("    movq            " "8 (%rdi), %rbx"),
        Q!("    movq            " "16 (%rdi), %rcx"),
        Q!("    movq            " "24 (%rdi), %rdx"),
        Q!("    movq            " "32 (%rdi), %r8"),
        Q!("    movq            " "40 (%rdi), %r9"),
        Q!("    movq            " "48 (%rdi), %r10"),
        Q!("    movq            " "56 (%rdi), %r11"),
        Q!("    jmp             " Label!(".Lloop_avx", 3, After)),
        Q!(Label!(".Lloop_avx", 3) ":"),
        Q!("    vmovdqa         " "{K512} + 1280 (%rip), %xmm11"),
        Q!("    movq            " "%rsi, -56 (%rbp)"),
        Q!("    vmovdqu         " "0 (%rsi), %xmm0"),
        Q!("    vmovdqu         " "16 (%rsi), %xmm1"),
        Q!("    vmovdqu         " "32 (%rsi), %xmm2"),
        Q!("    vpshufb         " "%xmm11, %xmm0, %xmm0"),
        Q!("    vmovdqu         " "48 (%rsi), %xmm3"),
        Q!("    vpshufb         " "%xmm11, %xmm1, %xmm1"),
        Q!("    vmovdqu         " "64 (%rsi), %xmm4"),
        Q!("    vpshufb         " "%xmm11, %xmm2, %xmm2"),
        Q!("    vmovdqu         " "80 (%rsi), %xmm5"),
        Q!("    vpshufb         " "%xmm11, %xmm3, %xmm3"),
        Q!("    vmovdqu         " "96 (%rsi), %xmm6"),
        Q!("    vpshufb         " "%xmm11, %xmm4, %xmm4"),
        Q!("    vmovdqu         " "112 (%rsi), %xmm7"),
        Q!("    leaq            " "{K512} + 128 (%rip), %rsi"),
        Q!("    vpshufb         " "%xmm11, %xmm5, %xmm5"),
        Q!("    vpaddq          " "-128 (%rsi), %xmm0, %xmm8"),
        Q!("    vpshufb         " "%xmm11, %xmm6, %xmm6"),
        Q!("    vpaddq          " "-96 (%rsi), %xmm1, %xmm9"),
        Q!("    vpshufb         " "%xmm11, %xmm7, %xmm7"),
        Q!("    vpaddq          " "-64 (%rsi), %xmm2, %xmm10"),
        Q!("    vpaddq          " "-32 (%rsi), %xmm3, %xmm11"),
        Q!("    vmovdqa         " "%xmm8, 0 (%rsp)"),
        Q!("    vpaddq          " "0 (%rsi), %xmm4, %xmm8"),
        Q!("    vmovdqa         " "%xmm9, 16 (%rsp)"),
        Q!("    vpaddq          " "32 (%rsi), %xmm5, %xmm9"),
        Q!("    vmovdqa         " "%xmm10, 32 (%rsp)"),
        Q!("    vpaddq          " "64 (%rsi), %xmm6, %xmm10"),
        Q!("    vmovdqa         " "%xmm11, 48 (%rsp)"),
        Q!("    vpaddq          " "96 (%rsi), %xmm7, %xmm11"),
        Q!("    vmovdqa         " "%xmm8, 64 (%rsp)"),
        Q!("    movq            " "%rax, %r14"),
        Q!("    vmovdqa         " "%xmm9, 80 (%rsp)"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vmovdqa         " "%xmm10, 96 (%rsp)"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    vmovdqa         " "%xmm11, 112 (%rsp)"),
        Q!("    movq            " "%r8, %r13"),
        Q!("    jmp             " Label!(".Lavx_00_47", 4, After)),
        Q!(Label!(".Lavx_00_47", 4) ":"),
        Q!("    addq            " "$256, %rsi"),
        Q!("    vpalignr        " "$8, %xmm0, %xmm1, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rax"),
        Q!("    vpalignr        " "$8, %xmm4, %xmm5, %xmm11"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm0, %xmm0"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "0 (%rsp), %r11"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    addq            " "%r12, %r11"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    addq            " "%r13, %r11"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm7, %xmm11"),
        Q!("    addq            " "%r11, %rdx"),
        Q!("    addq            " "%rdi, %r11"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%rdx, %r13"),
        Q!("    addq            " "%r11, %r14"),
        Q!("    vpsllq          " "$3, %xmm7, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r11"),
        Q!("    vpaddq          " "%xmm8, %xmm0, %xmm0"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm7, %xmm9"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "8 (%rsp), %r10"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    addq            " "%r12, %r10"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm0, %xmm0"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    addq            " "%r13, %r10"),
        Q!("    vpaddq          " "-128 (%rsi), %xmm0, %xmm10"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r10, %rcx"),
        Q!("    addq            " "%r15, %r10"),
        Q!("    movq            " "%rcx, %r13"),
        Q!("    addq            " "%r10, %r14"),
        Q!("    vmovdqa         " "%xmm10, 0 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm1, %xmm2, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r10"),
        Q!("    vpalignr        " "$8, %xmm5, %xmm6, %xmm11"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm1, %xmm1"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "16 (%rsp), %r9"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    addq            " "%r12, %r9"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    addq            " "%r13, %r9"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm0, %xmm11"),
        Q!("    addq            " "%r9, %rbx"),
        Q!("    addq            " "%rdi, %r9"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%rbx, %r13"),
        Q!("    addq            " "%r9, %r14"),
        Q!("    vpsllq          " "$3, %xmm0, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r9"),
        Q!("    vpaddq          " "%xmm8, %xmm1, %xmm1"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm0, %xmm9"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "24 (%rsp), %r8"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    addq            " "%r12, %r8"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm1, %xmm1"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    addq            " "%r13, %r8"),
        Q!("    vpaddq          " "-96 (%rsi), %xmm1, %xmm10"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r8, %rax"),
        Q!("    addq            " "%r15, %r8"),
        Q!("    movq            " "%rax, %r13"),
        Q!("    addq            " "%r8, %r14"),
        Q!("    vmovdqa         " "%xmm10, 16 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm2, %xmm3, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r8"),
        Q!("    vpalignr        " "$8, %xmm6, %xmm7, %xmm11"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm2, %xmm2"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "32 (%rsp), %rdx"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    addq            " "%r12, %rdx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    addq            " "%r13, %rdx"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm1, %xmm11"),
        Q!("    addq            " "%rdx, %r11"),
        Q!("    addq            " "%rdi, %rdx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%r11, %r13"),
        Q!("    addq            " "%rdx, %r14"),
        Q!("    vpsllq          " "$3, %xmm1, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rdx"),
        Q!("    vpaddq          " "%xmm8, %xmm2, %xmm2"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm1, %xmm9"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "40 (%rsp), %rcx"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    addq            " "%r12, %rcx"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm2, %xmm2"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    addq            " "%r13, %rcx"),
        Q!("    vpaddq          " "-64 (%rsi), %xmm2, %xmm10"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rcx, %r10"),
        Q!("    addq            " "%r15, %rcx"),
        Q!("    movq            " "%r10, %r13"),
        Q!("    addq            " "%rcx, %r14"),
        Q!("    vmovdqa         " "%xmm10, 32 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm3, %xmm4, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rcx"),
        Q!("    vpalignr        " "$8, %xmm7, %xmm0, %xmm11"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm3, %xmm3"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "48 (%rsp), %rbx"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    addq            " "%r12, %rbx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    addq            " "%r13, %rbx"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm2, %xmm11"),
        Q!("    addq            " "%rbx, %r9"),
        Q!("    addq            " "%rdi, %rbx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%r9, %r13"),
        Q!("    addq            " "%rbx, %r14"),
        Q!("    vpsllq          " "$3, %xmm2, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rbx"),
        Q!("    vpaddq          " "%xmm8, %xmm3, %xmm3"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm2, %xmm9"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "56 (%rsp), %rax"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    addq            " "%r12, %rax"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm3, %xmm3"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    addq            " "%r13, %rax"),
        Q!("    vpaddq          " "-32 (%rsi), %xmm3, %xmm10"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rax, %r8"),
        Q!("    addq            " "%r15, %rax"),
        Q!("    movq            " "%r8, %r13"),
        Q!("    addq            " "%rax, %r14"),
        Q!("    vmovdqa         " "%xmm10, 48 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm4, %xmm5, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rax"),
        Q!("    vpalignr        " "$8, %xmm0, %xmm1, %xmm11"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm4, %xmm4"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "64 (%rsp), %r11"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    addq            " "%r12, %r11"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    addq            " "%r13, %r11"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm3, %xmm11"),
        Q!("    addq            " "%r11, %rdx"),
        Q!("    addq            " "%rdi, %r11"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%rdx, %r13"),
        Q!("    addq            " "%r11, %r14"),
        Q!("    vpsllq          " "$3, %xmm3, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r11"),
        Q!("    vpaddq          " "%xmm8, %xmm4, %xmm4"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm3, %xmm9"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "72 (%rsp), %r10"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    addq            " "%r12, %r10"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm4, %xmm4"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    addq            " "%r13, %r10"),
        Q!("    vpaddq          " "0 (%rsi), %xmm4, %xmm10"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r10, %rcx"),
        Q!("    addq            " "%r15, %r10"),
        Q!("    movq            " "%rcx, %r13"),
        Q!("    addq            " "%r10, %r14"),
        Q!("    vmovdqa         " "%xmm10, 64 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm5, %xmm6, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r10"),
        Q!("    vpalignr        " "$8, %xmm1, %xmm2, %xmm11"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm5, %xmm5"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "80 (%rsp), %r9"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    addq            " "%r12, %r9"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    addq            " "%r13, %r9"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm4, %xmm11"),
        Q!("    addq            " "%r9, %rbx"),
        Q!("    addq            " "%rdi, %r9"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%rbx, %r13"),
        Q!("    addq            " "%r9, %r14"),
        Q!("    vpsllq          " "$3, %xmm4, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r9"),
        Q!("    vpaddq          " "%xmm8, %xmm5, %xmm5"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm4, %xmm9"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "88 (%rsp), %r8"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    addq            " "%r12, %r8"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm5, %xmm5"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    addq            " "%r13, %r8"),
        Q!("    vpaddq          " "32 (%rsi), %xmm5, %xmm10"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r8, %rax"),
        Q!("    addq            " "%r15, %r8"),
        Q!("    movq            " "%rax, %r13"),
        Q!("    addq            " "%r8, %r14"),
        Q!("    vmovdqa         " "%xmm10, 80 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm6, %xmm7, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r8"),
        Q!("    vpalignr        " "$8, %xmm2, %xmm3, %xmm11"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm6, %xmm6"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "96 (%rsp), %rdx"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    addq            " "%r12, %rdx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    addq            " "%r13, %rdx"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm5, %xmm11"),
        Q!("    addq            " "%rdx, %r11"),
        Q!("    addq            " "%rdi, %rdx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%r11, %r13"),
        Q!("    addq            " "%rdx, %r14"),
        Q!("    vpsllq          " "$3, %xmm5, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rdx"),
        Q!("    vpaddq          " "%xmm8, %xmm6, %xmm6"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm5, %xmm9"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "104 (%rsp), %rcx"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    addq            " "%r12, %rcx"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm6, %xmm6"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    addq            " "%r13, %rcx"),
        Q!("    vpaddq          " "64 (%rsi), %xmm6, %xmm10"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rcx, %r10"),
        Q!("    addq            " "%r15, %rcx"),
        Q!("    movq            " "%r10, %r13"),
        Q!("    addq            " "%rcx, %r14"),
        Q!("    vmovdqa         " "%xmm10, 96 (%rsp)"),
        Q!("    vpalignr        " "$8, %xmm7, %xmm0, %xmm8"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rcx"),
        Q!("    vpalignr        " "$8, %xmm3, %xmm4, %xmm11"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$1, %xmm8, %xmm10"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    vpaddq          " "%xmm11, %xmm7, %xmm7"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    vpsrlq          " "$7, %xmm8, %xmm11"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    vpsllq          " "$56, %xmm8, %xmm9"),
        Q!("    addq            " "112 (%rsp), %rbx"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm8"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpsrlq          " "$7, %xmm10, %xmm10"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    addq            " "%r12, %rbx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    vpsllq          " "$7, %xmm9, %xmm9"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    addq            " "%r13, %rbx"),
        Q!("    vpxor           " "%xmm10, %xmm8, %xmm8"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    vpsrlq          " "$6, %xmm6, %xmm11"),
        Q!("    addq            " "%rbx, %r9"),
        Q!("    addq            " "%rdi, %rbx"),
        Q!("    vpxor           " "%xmm9, %xmm8, %xmm8"),
        Q!("    movq            " "%r9, %r13"),
        Q!("    addq            " "%rbx, %r14"),
        Q!("    vpsllq          " "$3, %xmm6, %xmm10"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rbx"),
        Q!("    vpaddq          " "%xmm8, %xmm7, %xmm7"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    vpsrlq          " "$19, %xmm6, %xmm9"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    vpsllq          " "$42, %xmm10, %xmm10"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    addq            " "120 (%rsp), %rax"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vpsrlq          " "$42, %xmm9, %xmm9"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    vpxor           " "%xmm10, %xmm11, %xmm11"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    addq            " "%r12, %rax"),
        Q!("    vpxor           " "%xmm9, %xmm11, %xmm11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    vpaddq          " "%xmm11, %xmm7, %xmm7"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    addq            " "%r13, %rax"),
        Q!("    vpaddq          " "96 (%rsi), %xmm7, %xmm10"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rax, %r8"),
        Q!("    addq            " "%r15, %rax"),
        Q!("    movq            " "%r8, %r13"),
        Q!("    addq            " "%rax, %r14"),
        Q!("    vmovdqa         " "%xmm10, 112 (%rsp)"),
        Q!("    cmpb            " "$0, 135 (%rsi)"),
        Q!("    jne             " Label!(".Lavx_00_47", 4, Before)),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    addq            " "0 (%rsp), %r11"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    addq            " "%r12, %r11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    addq            " "%r13, %r11"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r11, %rdx"),
        Q!("    addq            " "%rdi, %r11"),
        Q!("    movq            " "%rdx, %r13"),
        Q!("    addq            " "%r11, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    addq            " "8 (%rsp), %r10"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    addq            " "%r12, %r10"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    addq            " "%r13, %r10"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r10, %rcx"),
        Q!("    addq            " "%r15, %r10"),
        Q!("    movq            " "%rcx, %r13"),
        Q!("    addq            " "%r10, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    addq            " "16 (%rsp), %r9"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    addq            " "%r12, %r9"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    addq            " "%r13, %r9"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r9, %rbx"),
        Q!("    addq            " "%rdi, %r9"),
        Q!("    movq            " "%rbx, %r13"),
        Q!("    addq            " "%r9, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    addq            " "24 (%rsp), %r8"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    addq            " "%r12, %r8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    addq            " "%r13, %r8"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r8, %rax"),
        Q!("    addq            " "%r15, %r8"),
        Q!("    movq            " "%rax, %r13"),
        Q!("    addq            " "%r8, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    addq            " "32 (%rsp), %rdx"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    addq            " "%r12, %rdx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    addq            " "%r13, %rdx"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rdx, %r11"),
        Q!("    addq            " "%rdi, %rdx"),
        Q!("    movq            " "%r11, %r13"),
        Q!("    addq            " "%rdx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    addq            " "40 (%rsp), %rcx"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    addq            " "%r12, %rcx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    addq            " "%r13, %rcx"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rcx, %r10"),
        Q!("    addq            " "%r15, %rcx"),
        Q!("    movq            " "%r10, %r13"),
        Q!("    addq            " "%rcx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    addq            " "48 (%rsp), %rbx"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    addq            " "%r12, %rbx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    addq            " "%r13, %rbx"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rbx, %r9"),
        Q!("    addq            " "%rdi, %rbx"),
        Q!("    movq            " "%r9, %r13"),
        Q!("    addq            " "%rbx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    addq            " "56 (%rsp), %rax"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    addq            " "%r12, %rax"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    addq            " "%r13, %rax"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rax, %r8"),
        Q!("    addq            " "%r15, %rax"),
        Q!("    movq            " "%r8, %r13"),
        Q!("    addq            " "%rax, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    xorq            " "%r8, %r13"),
        Q!("    addq            " "64 (%rsp), %r11"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    xorq            " "%r10, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    addq            " "%r12, %r11"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%rax, %r14"),
        Q!("    addq            " "%r13, %r11"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r11, %rdx"),
        Q!("    addq            " "%rdi, %r11"),
        Q!("    movq            " "%rdx, %r13"),
        Q!("    addq            " "%r11, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    xorq            " "%rdx, %r13"),
        Q!("    addq            " "72 (%rsp), %r10"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    xorq            " "%r9, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    addq            " "%r12, %r10"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r11, %r14"),
        Q!("    addq            " "%r13, %r10"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r10, %rcx"),
        Q!("    addq            " "%r15, %r10"),
        Q!("    movq            " "%rcx, %r13"),
        Q!("    addq            " "%r10, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    xorq            " "%rcx, %r13"),
        Q!("    addq            " "80 (%rsp), %r9"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    xorq            " "%r8, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    addq            " "%r12, %r9"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r10, %r14"),
        Q!("    addq            " "%r13, %r9"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r9, %rbx"),
        Q!("    addq            " "%rdi, %r9"),
        Q!("    movq            " "%rbx, %r13"),
        Q!("    addq            " "%r9, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    xorq            " "%rbx, %r13"),
        Q!("    addq            " "88 (%rsp), %r8"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    xorq            " "%rdx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    addq            " "%r12, %r8"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r9, %r14"),
        Q!("    addq            " "%r13, %r8"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%r8, %rax"),
        Q!("    addq            " "%r15, %r8"),
        Q!("    movq            " "%rax, %r13"),
        Q!("    addq            " "%r8, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    xorq            " "%rax, %r13"),
        Q!("    addq            " "96 (%rsp), %rdx"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    xorq            " "%rcx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    addq            " "%r12, %rdx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r8, %r14"),
        Q!("    addq            " "%r13, %rdx"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rdx, %r11"),
        Q!("    addq            " "%rdi, %rdx"),
        Q!("    movq            " "%r11, %r13"),
        Q!("    addq            " "%rdx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    xorq            " "%r11, %r13"),
        Q!("    addq            " "104 (%rsp), %rcx"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    xorq            " "%rbx, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    addq            " "%r12, %rcx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%rdx, %r14"),
        Q!("    addq            " "%r13, %rcx"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rcx, %r10"),
        Q!("    addq            " "%r15, %rcx"),
        Q!("    movq            " "%r10, %r13"),
        Q!("    addq            " "%rcx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    xorq            " "%r10, %r13"),
        Q!("    addq            " "112 (%rsp), %rbx"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    xorq            " "%rax, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    addq            " "%r12, %rbx"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%rcx, %r14"),
        Q!("    addq            " "%r13, %rbx"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rbx, %r9"),
        Q!("    addq            " "%rdi, %rbx"),
        Q!("    movq            " "%r9, %r13"),
        Q!("    addq            " "%rbx, %r14"),
        Q!("    shrdq           " "$23, %r13, %r13"),
        Q!("    movq            " "%r14, %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    shrdq           " "$5, %r14, %r14"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$4, %r13, %r13"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    xorq            " "%r9, %r13"),
        Q!("    addq            " "120 (%rsp), %rax"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    xorq            " "%r11, %r12"),
        Q!("    shrdq           " "$6, %r14, %r14"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    addq            " "%r12, %rax"),
        Q!("    shrdq           " "$14, %r13, %r13"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%rbx, %r14"),
        Q!("    addq            " "%r13, %rax"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    shrdq           " "$28, %r14, %r14"),
        Q!("    addq            " "%rax, %r8"),
        Q!("    addq            " "%r15, %rax"),
        Q!("    movq            " "%r8, %r13"),
        Q!("    addq            " "%rax, %r14"),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    movq            " "%r14, %rax"),
        Q!("    movq            " "-56 (%rbp), %rsi"),
        Q!("    addq            " "0 (%rdi), %rax"),
        Q!("    addq            " "8 (%rdi), %rbx"),
        Q!("    addq            " "16 (%rdi), %rcx"),
        Q!("    addq            " "24 (%rdi), %rdx"),
        Q!("    addq            " "32 (%rdi), %r8"),
        Q!("    addq            " "40 (%rdi), %r9"),
        Q!("    addq            " "48 (%rdi), %r10"),
        Q!("    addq            " "56 (%rdi), %r11"),
        Q!("    leaq            " "128 (%rsi), %rsi"),
        Q!("    cmpq            " "-48 (%rbp), %rsi"),
        Q!("    movq            " "%rax, 0 (%rdi)"),
        Q!("    movq            " "%rbx, 8 (%rdi)"),
        Q!("    movq            " "%rcx, 16 (%rdi)"),
        Q!("    movq            " "%rdx, 24 (%rdi)"),
        Q!("    movq            " "%r8, 32 (%rdi)"),
        Q!("    movq            " "%r9, 40 (%rdi)"),
        Q!("    movq            " "%r10, 48 (%rdi)"),
        Q!("    movq            " "%r11, 56 (%rdi)"),
        Q!("    jb              " Label!(".Lloop_avx", 3, Before)),
        Q!("    vzeroupper      " ),
        Q!("    movq            " "-40 (%rbp), %r15"),
        Q!("    movq            " "-32 (%rbp), %r14"),
        Q!("    movq            " "-24 (%rbp), %r13"),
        Q!("    movq            " "-16 (%rbp), %r12"),
        Q!("    movq            " "-8 (%rbp), %rbx"),
        Q!("    movq            " "%rbp, %rsp"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 128 => _,
        K512 = sym K512,
        // clobbers
        out("r10") _,
        out("r11") _,
        out("r12") _,
        out("r13") _,
        out("r14") _,
        out("r15") _,
        out("r8") _,
        out("r9") _,
        out("rax") _,
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm10") _,
        out("zmm11") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        options(att_syntax),
            )
    };
}

#[inline(never)]
pub fn sha512_block_data_order_avx2(state: &mut [u64; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lavx2_shortcut", 2) ":"),
        Q!("    pushq           " "%rbx"),
        Q!("    pushq           " "%r12"),
        Q!("    pushq           " "%r13"),
        Q!("    pushq           " "%r14"),
        Q!("    pushq           " "%r15"),
        Q!("    shlq            " "$4, %rdx"),
        Q!("    subq            " "$24, %rsp"),
        Q!("    leaq            " "(%rsi, %rdx, 8), %rdx"),
        Q!("    movq            " "%rdi, -64 (%rbp)"),
        Q!("    movq            " "%rdx, -48 (%rbp)"),
        Q!("    leaq            " "-128 (%rsp), %rsp"),
        Q!("    vzeroupper      " ),
        Q!("    andq            " "$-128, %rsp"),
        Q!("    subq            " "$-128, %rsi"),
        Q!("    movq            " "0 (%rdi), %rax"),
        Q!("    movq            " "%rsi, %r12"),
        Q!("    movq            " "8 (%rdi), %rbx"),
        Q!("    cmpq            " "%rdx, %rsi"),
        Q!("    movq            " "16 (%rdi), %rcx"),
        Q!("    cmoveq          " "%rsp, %r12"),
        Q!("    movq            " "24 (%rdi), %rdx"),
        Q!("    movq            " "32 (%rdi), %r8"),
        Q!("    movq            " "40 (%rdi), %r9"),
        Q!("    movq            " "48 (%rdi), %r10"),
        Q!("    movq            " "56 (%rdi), %r11"),
        Q!("    jmp             " Label!(".Loop_avx2", 3, After)),
        Q!(Label!(".Loop_avx2", 3) ":"),
        Q!("    vmovdqa         " "{K512} + 1280 (%rip), %ymm10"),
        Q!("    movq            " "%rsi, -56 (%rbp)"),
        Q!("    vmovdqu         " "-128 (%rsi), %xmm0"),
        Q!("    vmovdqu         " "-128 + 16 (%rsi), %xmm1"),
        Q!("    vmovdqu         " "-128 + 32 (%rsi), %xmm2"),
        Q!("    vmovdqu         " "-128 + 48 (%rsi), %xmm3"),
        Q!("    vmovdqu         " "-128 + 64 (%rsi), %xmm4"),
        Q!("    vmovdqu         " "-128 + 80 (%rsi), %xmm5"),
        Q!("    vmovdqu         " "-128 + 96 (%rsi), %xmm6"),
        Q!("    vmovdqu         " "-128 + 112 (%rsi), %xmm7"),
        Q!("    leaq            " "{K512} + 128 (%rip), %rsi"),
        Q!("    vinserti128     " "$1, (%r12), %ymm0, %ymm0"),
        Q!("    vinserti128     " "$1, 16 (%r12), %ymm1, %ymm1"),
        Q!("    vpshufb         " "%ymm10, %ymm0, %ymm0"),
        Q!("    vinserti128     " "$1, 32 (%r12), %ymm2, %ymm2"),
        Q!("    vpshufb         " "%ymm10, %ymm1, %ymm1"),
        Q!("    vinserti128     " "$1, 48 (%r12), %ymm3, %ymm3"),
        Q!("    vpshufb         " "%ymm10, %ymm2, %ymm2"),
        Q!("    vinserti128     " "$1, 64 (%r12), %ymm4, %ymm4"),
        Q!("    vpshufb         " "%ymm10, %ymm3, %ymm3"),
        Q!("    vinserti128     " "$1, 80 (%r12), %ymm5, %ymm5"),
        Q!("    vpshufb         " "%ymm10, %ymm4, %ymm4"),
        Q!("    vinserti128     " "$1, 96 (%r12), %ymm6, %ymm6"),
        Q!("    vpshufb         " "%ymm10, %ymm5, %ymm5"),
        Q!("    vinserti128     " "$1, 112 (%r12), %ymm7, %ymm7"),
        Q!("    vpaddq          " "-128 (%rsi), %ymm0, %ymm8"),
        Q!("    vpshufb         " "%ymm10, %ymm6, %ymm6"),
        Q!("    vpaddq          " "-96 (%rsi), %ymm1, %ymm9"),
        Q!("    vpshufb         " "%ymm10, %ymm7, %ymm7"),
        Q!("    vpaddq          " "-64 (%rsi), %ymm2, %ymm10"),
        Q!("    vpaddq          " "-32 (%rsi), %ymm3, %ymm11"),
        Q!("    vmovdqa         " "%ymm8, 0 (%rsp)"),
        Q!("    vpaddq          " "0 (%rsi), %ymm4, %ymm8"),
        Q!("    vmovdqa         " "%ymm9, 32 (%rsp)"),
        Q!("    vpaddq          " "32 (%rsi), %ymm5, %ymm9"),
        Q!("    vmovdqa         " "%ymm10, 64 (%rsp)"),
        Q!("    vpaddq          " "64 (%rsi), %ymm6, %ymm10"),
        Q!("    vmovdqa         " "%ymm11, 96 (%rsp)"),
        Q!("    leaq            " "-128 (%rsp), %rsp"),
        Q!("    vpaddq          " "96 (%rsi), %ymm7, %ymm11"),
        Q!("    vmovdqa         " "%ymm8, 0 (%rsp)"),
        Q!("    xorq            " "%r14, %r14"),
        Q!("    vmovdqa         " "%ymm9, 32 (%rsp)"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vmovdqa         " "%ymm10, 64 (%rsp)"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    vmovdqa         " "%ymm11, 96 (%rsp)"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    addq            " "$32 * 8, %rsi"),
        Q!("    jmp             " Label!(".Lavx2_00_47", 4, After)),
        Q!(Label!(".Lavx2_00_47", 4) ":"),
        Q!("    leaq            " "-128 (%rsp), %rsp"),
        Q!("    vpalignr        " "$8, %ymm0, %ymm1, %ymm8"),
        Q!("    addq            " "0 + 256 (%rsp), %r11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    rorxq           " "$41, %r8, %r13"),
        Q!("    vpalignr        " "$8, %ymm4, %ymm5, %ymm11"),
        Q!("    rorxq           " "$18, %r8, %r15"),
        Q!("    leaq            " "(%rax, %r14, 1), %rax"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%r10, %r8, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r8, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm0, %ymm0"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %rax, %r12"),
        Q!("    leaq            " "(%r11, %r13, 1), %r11"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %rax, %r14"),
        Q!("    rorxq           " "$28, %rax, %r13"),
        Q!("    leaq            " "(%rdx, %r11, 1), %rdx"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm7, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r11, %rdi, 1), %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    vpsllq          " "$3, %ymm7, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm0, %ymm0"),
        Q!("    addq            " "8 + 256 (%rsp), %r10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    rorxq           " "$41, %rdx, %r13"),
        Q!("    vpsrlq          " "$19, %ymm7, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %rdx, %rdi"),
        Q!("    leaq            " "(%r11, %r14, 1), %r11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%r9, %rdx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rdx, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %r11, %r12"),
        Q!("    leaq            " "(%r10, %r13, 1), %r10"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm0, %ymm0"),
        Q!("    rorxq           " "$34, %r11, %r14"),
        Q!("    rorxq           " "$28, %r11, %r13"),
        Q!("    leaq            " "(%rcx, %r10, 1), %rcx"),
        Q!("    vpaddq          " "-128 (%rsi), %ymm0, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r10, %r15, 1), %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    vmovdqa         " "%ymm10, 0 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm1, %ymm2, %ymm8"),
        Q!("    addq            " "32 + 256 (%rsp), %r9"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    rorxq           " "$41, %rcx, %r13"),
        Q!("    vpalignr        " "$8, %ymm5, %ymm6, %ymm11"),
        Q!("    rorxq           " "$18, %rcx, %r15"),
        Q!("    leaq            " "(%r10, %r14, 1), %r10"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%r8, %rcx, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rcx, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm1, %ymm1"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %r10, %r12"),
        Q!("    leaq            " "(%r9, %r13, 1), %r9"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %r10, %r14"),
        Q!("    rorxq           " "$28, %r10, %r13"),
        Q!("    leaq            " "(%rbx, %r9, 1), %rbx"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm0, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r9, %rdi, 1), %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    vpsllq          " "$3, %ymm0, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm1, %ymm1"),
        Q!("    addq            " "40 + 256 (%rsp), %r8"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    rorxq           " "$41, %rbx, %r13"),
        Q!("    vpsrlq          " "$19, %ymm0, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %rbx, %rdi"),
        Q!("    leaq            " "(%r9, %r14, 1), %r9"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%rdx, %rbx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rbx, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %r9, %r12"),
        Q!("    leaq            " "(%r8, %r13, 1), %r8"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm1, %ymm1"),
        Q!("    rorxq           " "$34, %r9, %r14"),
        Q!("    rorxq           " "$28, %r9, %r13"),
        Q!("    leaq            " "(%rax, %r8, 1), %rax"),
        Q!("    vpaddq          " "-96 (%rsi), %ymm1, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r8, %r15, 1), %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    vmovdqa         " "%ymm10, 32 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm2, %ymm3, %ymm8"),
        Q!("    addq            " "64 + 256 (%rsp), %rdx"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    rorxq           " "$41, %rax, %r13"),
        Q!("    vpalignr        " "$8, %ymm6, %ymm7, %ymm11"),
        Q!("    rorxq           " "$18, %rax, %r15"),
        Q!("    leaq            " "(%r8, %r14, 1), %r8"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%rcx, %rax, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rax, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm2, %ymm2"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %r8, %r12"),
        Q!("    leaq            " "(%rdx, %r13, 1), %rdx"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %r8, %r14"),
        Q!("    rorxq           " "$28, %r8, %r13"),
        Q!("    leaq            " "(%r11, %rdx, 1), %r11"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm1, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rdx, %rdi, 1), %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    vpsllq          " "$3, %ymm1, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm2, %ymm2"),
        Q!("    addq            " "72 + 256 (%rsp), %rcx"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    rorxq           " "$41, %r11, %r13"),
        Q!("    vpsrlq          " "$19, %ymm1, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %r11, %rdi"),
        Q!("    leaq            " "(%rdx, %r14, 1), %rdx"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%rbx, %r11, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r11, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %rdx, %r12"),
        Q!("    leaq            " "(%rcx, %r13, 1), %rcx"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm2, %ymm2"),
        Q!("    rorxq           " "$34, %rdx, %r14"),
        Q!("    rorxq           " "$28, %rdx, %r13"),
        Q!("    leaq            " "(%r10, %rcx, 1), %r10"),
        Q!("    vpaddq          " "-64 (%rsi), %ymm2, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rcx, %r15, 1), %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    vmovdqa         " "%ymm10, 64 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm3, %ymm4, %ymm8"),
        Q!("    addq            " "96 + 256 (%rsp), %rbx"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    rorxq           " "$41, %r10, %r13"),
        Q!("    vpalignr        " "$8, %ymm7, %ymm0, %ymm11"),
        Q!("    rorxq           " "$18, %r10, %r15"),
        Q!("    leaq            " "(%rcx, %r14, 1), %rcx"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%rax, %r10, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r10, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm3, %ymm3"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %rcx, %r12"),
        Q!("    leaq            " "(%rbx, %r13, 1), %rbx"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %rcx, %r14"),
        Q!("    rorxq           " "$28, %rcx, %r13"),
        Q!("    leaq            " "(%r9, %rbx, 1), %r9"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm2, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rbx, %rdi, 1), %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    vpsllq          " "$3, %ymm2, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm3, %ymm3"),
        Q!("    addq            " "104 + 256 (%rsp), %rax"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    rorxq           " "$41, %r9, %r13"),
        Q!("    vpsrlq          " "$19, %ymm2, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %r9, %rdi"),
        Q!("    leaq            " "(%rbx, %r14, 1), %rbx"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%r11, %r9, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r9, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %rbx, %r12"),
        Q!("    leaq            " "(%rax, %r13, 1), %rax"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm3, %ymm3"),
        Q!("    rorxq           " "$34, %rbx, %r14"),
        Q!("    rorxq           " "$28, %rbx, %r13"),
        Q!("    leaq            " "(%r8, %rax, 1), %r8"),
        Q!("    vpaddq          " "-32 (%rsi), %ymm3, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rax, %r15, 1), %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    vmovdqa         " "%ymm10, 96 (%rsp)"),
        Q!("    leaq            " "-128 (%rsp), %rsp"),
        Q!("    vpalignr        " "$8, %ymm4, %ymm5, %ymm8"),
        Q!("    addq            " "0 + 256 (%rsp), %r11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    rorxq           " "$41, %r8, %r13"),
        Q!("    vpalignr        " "$8, %ymm0, %ymm1, %ymm11"),
        Q!("    rorxq           " "$18, %r8, %r15"),
        Q!("    leaq            " "(%rax, %r14, 1), %rax"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%r10, %r8, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r8, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm4, %ymm4"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %rax, %r12"),
        Q!("    leaq            " "(%r11, %r13, 1), %r11"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %rax, %r14"),
        Q!("    rorxq           " "$28, %rax, %r13"),
        Q!("    leaq            " "(%rdx, %r11, 1), %rdx"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm3, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r11, %rdi, 1), %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    vpsllq          " "$3, %ymm3, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm4, %ymm4"),
        Q!("    addq            " "8 + 256 (%rsp), %r10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    rorxq           " "$41, %rdx, %r13"),
        Q!("    vpsrlq          " "$19, %ymm3, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %rdx, %rdi"),
        Q!("    leaq            " "(%r11, %r14, 1), %r11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%r9, %rdx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rdx, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %r11, %r12"),
        Q!("    leaq            " "(%r10, %r13, 1), %r10"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm4, %ymm4"),
        Q!("    rorxq           " "$34, %r11, %r14"),
        Q!("    rorxq           " "$28, %r11, %r13"),
        Q!("    leaq            " "(%rcx, %r10, 1), %rcx"),
        Q!("    vpaddq          " "0 (%rsi), %ymm4, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r10, %r15, 1), %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    vmovdqa         " "%ymm10, 0 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm5, %ymm6, %ymm8"),
        Q!("    addq            " "32 + 256 (%rsp), %r9"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    rorxq           " "$41, %rcx, %r13"),
        Q!("    vpalignr        " "$8, %ymm1, %ymm2, %ymm11"),
        Q!("    rorxq           " "$18, %rcx, %r15"),
        Q!("    leaq            " "(%r10, %r14, 1), %r10"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%r8, %rcx, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rcx, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm5, %ymm5"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %r10, %r12"),
        Q!("    leaq            " "(%r9, %r13, 1), %r9"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %r10, %r14"),
        Q!("    rorxq           " "$28, %r10, %r13"),
        Q!("    leaq            " "(%rbx, %r9, 1), %rbx"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm4, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r9, %rdi, 1), %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    vpsllq          " "$3, %ymm4, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm5, %ymm5"),
        Q!("    addq            " "40 + 256 (%rsp), %r8"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    rorxq           " "$41, %rbx, %r13"),
        Q!("    vpsrlq          " "$19, %ymm4, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %rbx, %rdi"),
        Q!("    leaq            " "(%r9, %r14, 1), %r9"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%rdx, %rbx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rbx, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %r9, %r12"),
        Q!("    leaq            " "(%r8, %r13, 1), %r8"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm5, %ymm5"),
        Q!("    rorxq           " "$34, %r9, %r14"),
        Q!("    rorxq           " "$28, %r9, %r13"),
        Q!("    leaq            " "(%rax, %r8, 1), %rax"),
        Q!("    vpaddq          " "32 (%rsi), %ymm5, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r8, %r15, 1), %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    vmovdqa         " "%ymm10, 32 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm6, %ymm7, %ymm8"),
        Q!("    addq            " "64 + 256 (%rsp), %rdx"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    rorxq           " "$41, %rax, %r13"),
        Q!("    vpalignr        " "$8, %ymm2, %ymm3, %ymm11"),
        Q!("    rorxq           " "$18, %rax, %r15"),
        Q!("    leaq            " "(%r8, %r14, 1), %r8"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%rcx, %rax, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rax, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm6, %ymm6"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %r8, %r12"),
        Q!("    leaq            " "(%rdx, %r13, 1), %rdx"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %r8, %r14"),
        Q!("    rorxq           " "$28, %r8, %r13"),
        Q!("    leaq            " "(%r11, %rdx, 1), %r11"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm5, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rdx, %rdi, 1), %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    vpsllq          " "$3, %ymm5, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm6, %ymm6"),
        Q!("    addq            " "72 + 256 (%rsp), %rcx"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    rorxq           " "$41, %r11, %r13"),
        Q!("    vpsrlq          " "$19, %ymm5, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %r11, %rdi"),
        Q!("    leaq            " "(%rdx, %r14, 1), %rdx"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%rbx, %r11, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r11, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %rdx, %r12"),
        Q!("    leaq            " "(%rcx, %r13, 1), %rcx"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm6, %ymm6"),
        Q!("    rorxq           " "$34, %rdx, %r14"),
        Q!("    rorxq           " "$28, %rdx, %r13"),
        Q!("    leaq            " "(%r10, %rcx, 1), %r10"),
        Q!("    vpaddq          " "64 (%rsi), %ymm6, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rcx, %r15, 1), %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    vmovdqa         " "%ymm10, 64 (%rsp)"),
        Q!("    vpalignr        " "$8, %ymm7, %ymm0, %ymm8"),
        Q!("    addq            " "96 + 256 (%rsp), %rbx"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    rorxq           " "$41, %r10, %r13"),
        Q!("    vpalignr        " "$8, %ymm3, %ymm4, %ymm11"),
        Q!("    rorxq           " "$18, %r10, %r15"),
        Q!("    leaq            " "(%rcx, %r14, 1), %rcx"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    vpsrlq          " "$1, %ymm8, %ymm10"),
        Q!("    andnq           " "%rax, %r10, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r10, %r14"),
        Q!("    vpaddq          " "%ymm11, %ymm7, %ymm7"),
        Q!("    vpsrlq          " "$7, %ymm8, %ymm11"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    vpsllq          " "$56, %ymm8, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm8"),
        Q!("    rorxq           " "$39, %rcx, %r12"),
        Q!("    leaq            " "(%rbx, %r13, 1), %rbx"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    vpsrlq          " "$7, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    rorxq           " "$34, %rcx, %r14"),
        Q!("    rorxq           " "$28, %rcx, %r13"),
        Q!("    leaq            " "(%r9, %rbx, 1), %r9"),
        Q!("    vpsllq          " "$7, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm8, %ymm8"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    vpsrlq          " "$6, %ymm6, %ymm11"),
        Q!("    vpxor           " "%ymm9, %ymm8, %ymm8"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rbx, %rdi, 1), %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    vpsllq          " "$3, %ymm6, %ymm10"),
        Q!("    vpaddq          " "%ymm8, %ymm7, %ymm7"),
        Q!("    addq            " "104 + 256 (%rsp), %rax"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    rorxq           " "$41, %r9, %r13"),
        Q!("    vpsrlq          " "$19, %ymm6, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    rorxq           " "$18, %r9, %rdi"),
        Q!("    leaq            " "(%rbx, %r14, 1), %rbx"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    vpsllq          " "$42, %ymm10, %ymm10"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    andnq           " "%r11, %r9, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r9, %r14"),
        Q!("    vpsrlq          " "$42, %ymm9, %ymm9"),
        Q!("    vpxor           " "%ymm10, %ymm11, %ymm11"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    vpxor           " "%ymm9, %ymm11, %ymm11"),
        Q!("    rorxq           " "$39, %rbx, %r12"),
        Q!("    leaq            " "(%rax, %r13, 1), %rax"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    vpaddq          " "%ymm11, %ymm7, %ymm7"),
        Q!("    rorxq           " "$34, %rbx, %r14"),
        Q!("    rorxq           " "$28, %rbx, %r13"),
        Q!("    leaq            " "(%r8, %rax, 1), %r8"),
        Q!("    vpaddq          " "96 (%rsi), %ymm7, %ymm10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rax, %r15, 1), %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    vmovdqa         " "%ymm10, 96 (%rsp)"),
        Q!("    leaq            " "256 (%rsi), %rsi"),
        Q!("    cmpb            " "$0, -121 (%rsi)"),
        Q!("    jne             " Label!(".Lavx2_00_47", 4, Before)),
        Q!("    addq            " "0 + 128 (%rsp), %r11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    rorxq           " "$41, %r8, %r13"),
        Q!("    rorxq           " "$18, %r8, %r15"),
        Q!("    leaq            " "(%rax, %r14, 1), %rax"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    andnq           " "%r10, %r8, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r8, %r14"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    rorxq           " "$39, %rax, %r12"),
        Q!("    leaq            " "(%r11, %r13, 1), %r11"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    rorxq           " "$34, %rax, %r14"),
        Q!("    rorxq           " "$28, %rax, %r13"),
        Q!("    leaq            " "(%rdx, %r11, 1), %rdx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r11, %rdi, 1), %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    addq            " "8 + 128 (%rsp), %r10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    rorxq           " "$41, %rdx, %r13"),
        Q!("    rorxq           " "$18, %rdx, %rdi"),
        Q!("    leaq            " "(%r11, %r14, 1), %r11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    andnq           " "%r9, %rdx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rdx, %r14"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    rorxq           " "$39, %r11, %r12"),
        Q!("    leaq            " "(%r10, %r13, 1), %r10"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    rorxq           " "$34, %r11, %r14"),
        Q!("    rorxq           " "$28, %r11, %r13"),
        Q!("    leaq            " "(%rcx, %r10, 1), %rcx"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r10, %r15, 1), %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    addq            " "32 + 128 (%rsp), %r9"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    rorxq           " "$41, %rcx, %r13"),
        Q!("    rorxq           " "$18, %rcx, %r15"),
        Q!("    leaq            " "(%r10, %r14, 1), %r10"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    andnq           " "%r8, %rcx, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rcx, %r14"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    rorxq           " "$39, %r10, %r12"),
        Q!("    leaq            " "(%r9, %r13, 1), %r9"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    rorxq           " "$34, %r10, %r14"),
        Q!("    rorxq           " "$28, %r10, %r13"),
        Q!("    leaq            " "(%rbx, %r9, 1), %rbx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r9, %rdi, 1), %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    addq            " "40 + 128 (%rsp), %r8"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    rorxq           " "$41, %rbx, %r13"),
        Q!("    rorxq           " "$18, %rbx, %rdi"),
        Q!("    leaq            " "(%r9, %r14, 1), %r9"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    andnq           " "%rdx, %rbx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rbx, %r14"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    rorxq           " "$39, %r9, %r12"),
        Q!("    leaq            " "(%r8, %r13, 1), %r8"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    rorxq           " "$34, %r9, %r14"),
        Q!("    rorxq           " "$28, %r9, %r13"),
        Q!("    leaq            " "(%rax, %r8, 1), %rax"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r8, %r15, 1), %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    addq            " "64 + 128 (%rsp), %rdx"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    rorxq           " "$41, %rax, %r13"),
        Q!("    rorxq           " "$18, %rax, %r15"),
        Q!("    leaq            " "(%r8, %r14, 1), %r8"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    andnq           " "%rcx, %rax, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rax, %r14"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    rorxq           " "$39, %r8, %r12"),
        Q!("    leaq            " "(%rdx, %r13, 1), %rdx"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    rorxq           " "$34, %r8, %r14"),
        Q!("    rorxq           " "$28, %r8, %r13"),
        Q!("    leaq            " "(%r11, %rdx, 1), %r11"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rdx, %rdi, 1), %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    addq            " "72 + 128 (%rsp), %rcx"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    rorxq           " "$41, %r11, %r13"),
        Q!("    rorxq           " "$18, %r11, %rdi"),
        Q!("    leaq            " "(%rdx, %r14, 1), %rdx"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    andnq           " "%rbx, %r11, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r11, %r14"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    rorxq           " "$39, %rdx, %r12"),
        Q!("    leaq            " "(%rcx, %r13, 1), %rcx"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    rorxq           " "$34, %rdx, %r14"),
        Q!("    rorxq           " "$28, %rdx, %r13"),
        Q!("    leaq            " "(%r10, %rcx, 1), %r10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rcx, %r15, 1), %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    addq            " "96 + 128 (%rsp), %rbx"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    rorxq           " "$41, %r10, %r13"),
        Q!("    rorxq           " "$18, %r10, %r15"),
        Q!("    leaq            " "(%rcx, %r14, 1), %rcx"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    andnq           " "%rax, %r10, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r10, %r14"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    rorxq           " "$39, %rcx, %r12"),
        Q!("    leaq            " "(%rbx, %r13, 1), %rbx"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    rorxq           " "$34, %rcx, %r14"),
        Q!("    rorxq           " "$28, %rcx, %r13"),
        Q!("    leaq            " "(%r9, %rbx, 1), %r9"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rbx, %rdi, 1), %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    addq            " "104 + 128 (%rsp), %rax"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    rorxq           " "$41, %r9, %r13"),
        Q!("    rorxq           " "$18, %r9, %rdi"),
        Q!("    leaq            " "(%rbx, %r14, 1), %rbx"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    andnq           " "%r11, %r9, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r9, %r14"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    rorxq           " "$39, %rbx, %r12"),
        Q!("    leaq            " "(%rax, %r13, 1), %rax"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    rorxq           " "$34, %rbx, %r14"),
        Q!("    rorxq           " "$28, %rbx, %r13"),
        Q!("    leaq            " "(%r8, %rax, 1), %r8"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rax, %r15, 1), %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    addq            " "0 (%rsp), %r11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    rorxq           " "$41, %r8, %r13"),
        Q!("    rorxq           " "$18, %r8, %r15"),
        Q!("    leaq            " "(%rax, %r14, 1), %rax"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    andnq           " "%r10, %r8, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r8, %r14"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    rorxq           " "$39, %rax, %r12"),
        Q!("    leaq            " "(%r11, %r13, 1), %r11"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    rorxq           " "$34, %rax, %r14"),
        Q!("    rorxq           " "$28, %rax, %r13"),
        Q!("    leaq            " "(%rdx, %r11, 1), %rdx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r11, %rdi, 1), %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    addq            " "8 (%rsp), %r10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    rorxq           " "$41, %rdx, %r13"),
        Q!("    rorxq           " "$18, %rdx, %rdi"),
        Q!("    leaq            " "(%r11, %r14, 1), %r11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    andnq           " "%r9, %rdx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rdx, %r14"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    rorxq           " "$39, %r11, %r12"),
        Q!("    leaq            " "(%r10, %r13, 1), %r10"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    rorxq           " "$34, %r11, %r14"),
        Q!("    rorxq           " "$28, %r11, %r13"),
        Q!("    leaq            " "(%rcx, %r10, 1), %rcx"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r10, %r15, 1), %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    addq            " "32 (%rsp), %r9"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    rorxq           " "$41, %rcx, %r13"),
        Q!("    rorxq           " "$18, %rcx, %r15"),
        Q!("    leaq            " "(%r10, %r14, 1), %r10"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    andnq           " "%r8, %rcx, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rcx, %r14"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    rorxq           " "$39, %r10, %r12"),
        Q!("    leaq            " "(%r9, %r13, 1), %r9"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    rorxq           " "$34, %r10, %r14"),
        Q!("    rorxq           " "$28, %r10, %r13"),
        Q!("    leaq            " "(%rbx, %r9, 1), %rbx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r9, %rdi, 1), %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    addq            " "40 (%rsp), %r8"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    rorxq           " "$41, %rbx, %r13"),
        Q!("    rorxq           " "$18, %rbx, %rdi"),
        Q!("    leaq            " "(%r9, %r14, 1), %r9"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    andnq           " "%rdx, %rbx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rbx, %r14"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    rorxq           " "$39, %r9, %r12"),
        Q!("    leaq            " "(%r8, %r13, 1), %r8"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    rorxq           " "$34, %r9, %r14"),
        Q!("    rorxq           " "$28, %r9, %r13"),
        Q!("    leaq            " "(%rax, %r8, 1), %rax"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r8, %r15, 1), %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    addq            " "64 (%rsp), %rdx"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    rorxq           " "$41, %rax, %r13"),
        Q!("    rorxq           " "$18, %rax, %r15"),
        Q!("    leaq            " "(%r8, %r14, 1), %r8"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    andnq           " "%rcx, %rax, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rax, %r14"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    rorxq           " "$39, %r8, %r12"),
        Q!("    leaq            " "(%rdx, %r13, 1), %rdx"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    rorxq           " "$34, %r8, %r14"),
        Q!("    rorxq           " "$28, %r8, %r13"),
        Q!("    leaq            " "(%r11, %rdx, 1), %r11"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rdx, %rdi, 1), %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    addq            " "72 (%rsp), %rcx"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    rorxq           " "$41, %r11, %r13"),
        Q!("    rorxq           " "$18, %r11, %rdi"),
        Q!("    leaq            " "(%rdx, %r14, 1), %rdx"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    andnq           " "%rbx, %r11, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r11, %r14"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    rorxq           " "$39, %rdx, %r12"),
        Q!("    leaq            " "(%rcx, %r13, 1), %rcx"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    rorxq           " "$34, %rdx, %r14"),
        Q!("    rorxq           " "$28, %rdx, %r13"),
        Q!("    leaq            " "(%r10, %rcx, 1), %r10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rcx, %r15, 1), %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    addq            " "96 (%rsp), %rbx"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    rorxq           " "$41, %r10, %r13"),
        Q!("    rorxq           " "$18, %r10, %r15"),
        Q!("    leaq            " "(%rcx, %r14, 1), %rcx"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    andnq           " "%rax, %r10, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r10, %r14"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    rorxq           " "$39, %rcx, %r12"),
        Q!("    leaq            " "(%rbx, %r13, 1), %rbx"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    rorxq           " "$34, %rcx, %r14"),
        Q!("    rorxq           " "$28, %rcx, %r13"),
        Q!("    leaq            " "(%r9, %rbx, 1), %r9"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rbx, %rdi, 1), %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    addq            " "104 (%rsp), %rax"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    rorxq           " "$41, %r9, %r13"),
        Q!("    rorxq           " "$18, %r9, %rdi"),
        Q!("    leaq            " "(%rbx, %r14, 1), %rbx"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    andnq           " "%r11, %r9, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r9, %r14"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    rorxq           " "$39, %rbx, %r12"),
        Q!("    leaq            " "(%rax, %r13, 1), %rax"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    rorxq           " "$34, %rbx, %r14"),
        Q!("    rorxq           " "$28, %rbx, %r13"),
        Q!("    leaq            " "(%r8, %rax, 1), %r8"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rax, %r15, 1), %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    addq            " "%r14, %rax"),
        Q!("    movq            " "-56 (%rbp), %r12"),
        Q!("    addq            " "0 (%rdi), %rax"),
        Q!("    addq            " "8 (%rdi), %rbx"),
        Q!("    addq            " "16 (%rdi), %rcx"),
        Q!("    addq            " "24 (%rdi), %rdx"),
        Q!("    addq            " "32 (%rdi), %r8"),
        Q!("    addq            " "40 (%rdi), %r9"),
        Q!("    addq            " "48 (%rdi), %r10"),
        Q!("    addq            " "56 (%rdi), %r11"),
        Q!("    movq            " "%rax, 0 (%rdi)"),
        Q!("    movq            " "%rbx, 8 (%rdi)"),
        Q!("    movq            " "%rcx, 16 (%rdi)"),
        Q!("    movq            " "%rdx, 24 (%rdi)"),
        Q!("    movq            " "%r8, 32 (%rdi)"),
        Q!("    movq            " "%r9, 40 (%rdi)"),
        Q!("    movq            " "%r10, 48 (%rdi)"),
        Q!("    movq            " "%r11, 56 (%rdi)"),
        Q!("    cmpq            " "-48 (%rbp), %r12"),
        Q!("    je              " Label!(".Ldone_avx2", 5, After)),
        Q!("    leaq            " "1152 (%rsp), %rsi"),
        Q!("    xorq            " "%r14, %r14"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    jmp             " Label!(".Lower_avx2", 6, After)),
        Q!(Label!(".Lower_avx2", 6) ":"),
        Q!("    addq            " "0 + 16 (%rsi), %r11"),
        Q!("    andq            " "%r8, %r12"),
        Q!("    rorxq           " "$41, %r8, %r13"),
        Q!("    rorxq           " "$18, %r8, %r15"),
        Q!("    leaq            " "(%rax, %r14, 1), %rax"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    andnq           " "%r10, %r8, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r8, %r14"),
        Q!("    leaq            " "(%r11, %r12, 1), %r11"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rax, %r15"),
        Q!("    rorxq           " "$39, %rax, %r12"),
        Q!("    leaq            " "(%r11, %r13, 1), %r11"),
        Q!("    xorq            " "%rbx, %r15"),
        Q!("    rorxq           " "$34, %rax, %r14"),
        Q!("    rorxq           " "$28, %rax, %r13"),
        Q!("    leaq            " "(%rdx, %r11, 1), %rdx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rbx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r11, %rdi, 1), %r11"),
        Q!("    movq            " "%r8, %r12"),
        Q!("    addq            " "8 + 16 (%rsi), %r10"),
        Q!("    andq            " "%rdx, %r12"),
        Q!("    rorxq           " "$41, %rdx, %r13"),
        Q!("    rorxq           " "$18, %rdx, %rdi"),
        Q!("    leaq            " "(%r11, %r14, 1), %r11"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    andnq           " "%r9, %rdx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rdx, %r14"),
        Q!("    leaq            " "(%r10, %r12, 1), %r10"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r11, %rdi"),
        Q!("    rorxq           " "$39, %r11, %r12"),
        Q!("    leaq            " "(%r10, %r13, 1), %r10"),
        Q!("    xorq            " "%rax, %rdi"),
        Q!("    rorxq           " "$34, %r11, %r14"),
        Q!("    rorxq           " "$28, %r11, %r13"),
        Q!("    leaq            " "(%rcx, %r10, 1), %rcx"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rax, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r10, %r15, 1), %r10"),
        Q!("    movq            " "%rdx, %r12"),
        Q!("    addq            " "32 + 16 (%rsi), %r9"),
        Q!("    andq            " "%rcx, %r12"),
        Q!("    rorxq           " "$41, %rcx, %r13"),
        Q!("    rorxq           " "$18, %rcx, %r15"),
        Q!("    leaq            " "(%r10, %r14, 1), %r10"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    andnq           " "%r8, %rcx, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rcx, %r14"),
        Q!("    leaq            " "(%r9, %r12, 1), %r9"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r10, %r15"),
        Q!("    rorxq           " "$39, %r10, %r12"),
        Q!("    leaq            " "(%r9, %r13, 1), %r9"),
        Q!("    xorq            " "%r11, %r15"),
        Q!("    rorxq           " "$34, %r10, %r14"),
        Q!("    rorxq           " "$28, %r10, %r13"),
        Q!("    leaq            " "(%rbx, %r9, 1), %rbx"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r11, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r9, %rdi, 1), %r9"),
        Q!("    movq            " "%rcx, %r12"),
        Q!("    addq            " "40 + 16 (%rsi), %r8"),
        Q!("    andq            " "%rbx, %r12"),
        Q!("    rorxq           " "$41, %rbx, %r13"),
        Q!("    rorxq           " "$18, %rbx, %rdi"),
        Q!("    leaq            " "(%r9, %r14, 1), %r9"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    andnq           " "%rdx, %rbx, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %rbx, %r14"),
        Q!("    leaq            " "(%r8, %r12, 1), %r8"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r9, %rdi"),
        Q!("    rorxq           " "$39, %r9, %r12"),
        Q!("    leaq            " "(%r8, %r13, 1), %r8"),
        Q!("    xorq            " "%r10, %rdi"),
        Q!("    rorxq           " "$34, %r9, %r14"),
        Q!("    rorxq           " "$28, %r9, %r13"),
        Q!("    leaq            " "(%rax, %r8, 1), %rax"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r10, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%r8, %r15, 1), %r8"),
        Q!("    movq            " "%rbx, %r12"),
        Q!("    addq            " "64 + 16 (%rsi), %rdx"),
        Q!("    andq            " "%rax, %r12"),
        Q!("    rorxq           " "$41, %rax, %r13"),
        Q!("    rorxq           " "$18, %rax, %r15"),
        Q!("    leaq            " "(%r8, %r14, 1), %r8"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    andnq           " "%rcx, %rax, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %rax, %r14"),
        Q!("    leaq            " "(%rdx, %r12, 1), %rdx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%r8, %r15"),
        Q!("    rorxq           " "$39, %r8, %r12"),
        Q!("    leaq            " "(%rdx, %r13, 1), %rdx"),
        Q!("    xorq            " "%r9, %r15"),
        Q!("    rorxq           " "$34, %r8, %r14"),
        Q!("    rorxq           " "$28, %r8, %r13"),
        Q!("    leaq            " "(%r11, %rdx, 1), %r11"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r9, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rdx, %rdi, 1), %rdx"),
        Q!("    movq            " "%rax, %r12"),
        Q!("    addq            " "72 + 16 (%rsi), %rcx"),
        Q!("    andq            " "%r11, %r12"),
        Q!("    rorxq           " "$41, %r11, %r13"),
        Q!("    rorxq           " "$18, %r11, %rdi"),
        Q!("    leaq            " "(%rdx, %r14, 1), %rdx"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    andnq           " "%rbx, %r11, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r11, %r14"),
        Q!("    leaq            " "(%rcx, %r12, 1), %rcx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rdx, %rdi"),
        Q!("    rorxq           " "$39, %rdx, %r12"),
        Q!("    leaq            " "(%rcx, %r13, 1), %rcx"),
        Q!("    xorq            " "%r8, %rdi"),
        Q!("    rorxq           " "$34, %rdx, %r14"),
        Q!("    rorxq           " "$28, %rdx, %r13"),
        Q!("    leaq            " "(%r10, %rcx, 1), %r10"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%r8, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rcx, %r15, 1), %rcx"),
        Q!("    movq            " "%r11, %r12"),
        Q!("    addq            " "96 + 16 (%rsi), %rbx"),
        Q!("    andq            " "%r10, %r12"),
        Q!("    rorxq           " "$41, %r10, %r13"),
        Q!("    rorxq           " "$18, %r10, %r15"),
        Q!("    leaq            " "(%rcx, %r14, 1), %rcx"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    andnq           " "%rax, %r10, %r12"),
        Q!("    xorq            " "%r15, %r13"),
        Q!("    rorxq           " "$14, %r10, %r14"),
        Q!("    leaq            " "(%rbx, %r12, 1), %rbx"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rcx, %r15"),
        Q!("    rorxq           " "$39, %rcx, %r12"),
        Q!("    leaq            " "(%rbx, %r13, 1), %rbx"),
        Q!("    xorq            " "%rdx, %r15"),
        Q!("    rorxq           " "$34, %rcx, %r14"),
        Q!("    rorxq           " "$28, %rcx, %r13"),
        Q!("    leaq            " "(%r9, %rbx, 1), %r9"),
        Q!("    andq            " "%r15, %rdi"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rdx, %rdi"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rbx, %rdi, 1), %rbx"),
        Q!("    movq            " "%r10, %r12"),
        Q!("    addq            " "104 + 16 (%rsi), %rax"),
        Q!("    andq            " "%r9, %r12"),
        Q!("    rorxq           " "$41, %r9, %r13"),
        Q!("    rorxq           " "$18, %r9, %rdi"),
        Q!("    leaq            " "(%rbx, %r14, 1), %rbx"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    andnq           " "%r11, %r9, %r12"),
        Q!("    xorq            " "%rdi, %r13"),
        Q!("    rorxq           " "$14, %r9, %r14"),
        Q!("    leaq            " "(%rax, %r12, 1), %rax"),
        Q!("    xorq            " "%r14, %r13"),
        Q!("    movq            " "%rbx, %rdi"),
        Q!("    rorxq           " "$39, %rbx, %r12"),
        Q!("    leaq            " "(%rax, %r13, 1), %rax"),
        Q!("    xorq            " "%rcx, %rdi"),
        Q!("    rorxq           " "$34, %rbx, %r14"),
        Q!("    rorxq           " "$28, %rbx, %r13"),
        Q!("    leaq            " "(%r8, %rax, 1), %r8"),
        Q!("    andq            " "%rdi, %r15"),
        Q!("    xorq            " "%r12, %r14"),
        Q!("    xorq            " "%rcx, %r15"),
        Q!("    xorq            " "%r13, %r14"),
        Q!("    leaq            " "(%rax, %r15, 1), %rax"),
        Q!("    movq            " "%r9, %r12"),
        Q!("    leaq            " "-128 (%rsi), %rsi"),
        Q!("    cmpq            " "%rsp, %rsi"),
        Q!("    jae             " Label!(".Lower_avx2", 6, Before)),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    addq            " "%r14, %rax"),
        Q!("    movq            " "-56 (%rbp), %rsi"),
        Q!("    leaq            " "1152 (%rsp), %rsp"),
        Q!("    addq            " "0 (%rdi), %rax"),
        Q!("    addq            " "8 (%rdi), %rbx"),
        Q!("    addq            " "16 (%rdi), %rcx"),
        Q!("    addq            " "24 (%rdi), %rdx"),
        Q!("    addq            " "32 (%rdi), %r8"),
        Q!("    addq            " "40 (%rdi), %r9"),
        Q!("    leaq            " "256 (%rsi), %rsi"),
        Q!("    addq            " "48 (%rdi), %r10"),
        Q!("    movq            " "%rsi, %r12"),
        Q!("    addq            " "56 (%rdi), %r11"),
        Q!("    cmpq            " "-48 (%rbp), %rsi"),
        Q!("    movq            " "%rax, 0 (%rdi)"),
        Q!("    cmoveq          " "%rsp, %r12"),
        Q!("    movq            " "%rbx, 8 (%rdi)"),
        Q!("    movq            " "%rcx, 16 (%rdi)"),
        Q!("    movq            " "%rdx, 24 (%rdi)"),
        Q!("    movq            " "%r8, 32 (%rdi)"),
        Q!("    movq            " "%r9, 40 (%rdi)"),
        Q!("    movq            " "%r10, 48 (%rdi)"),
        Q!("    movq            " "%r11, 56 (%rdi)"),
        Q!("    jbe             " Label!(".Loop_avx2", 3, Before)),
        Q!(Label!(".Ldone_avx2", 5) ":"),
        Q!("    vzeroupper      " ),
        Q!("    movq            " "-40 (%rbp), %r15"),
        Q!("    movq            " "-32 (%rbp), %r14"),
        Q!("    movq            " "-24 (%rbp), %r13"),
        Q!("    movq            " "-16 (%rbp), %r12"),
        Q!("    movq            " "-8 (%rbp), %rbx"),
        Q!("    movq            " "%rbp, %rsp"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 128 => _,
        K512 = sym K512,
        // clobbers
        out("r10") _,
        out("r11") _,
        out("r12") _,
        out("r13") _,
        out("r14") _,
        out("r15") _,
        out("r8") _,
        out("r9") _,
        out("rax") _,
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm10") _,
        out("zmm11") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        options(att_syntax),
            )
    };
}
#[allow(dead_code)]
#[repr(align(64))]
struct B64Alignedu64Array80([u64; 80]);

static K512_nodup: B64Alignedu64Array80 = B64Alignedu64Array80([
    0x428a2f98d728ae22,
    0x7137449123ef65cd,
    0xb5c0fbcfec4d3b2f,
    0xe9b5dba58189dbbc,
    0x3956c25bf348b538,
    0x59f111f1b605d019,
    0x923f82a4af194f9b,
    0xab1c5ed5da6d8118,
    0xd807aa98a3030242,
    0x12835b0145706fbe,
    0x243185be4ee4b28c,
    0x550c7dc3d5ffb4e2,
    0x72be5d74f27b896f,
    0x80deb1fe3b1696b1,
    0x9bdc06a725c71235,
    0xc19bf174cf692694,
    0xe49b69c19ef14ad2,
    0xefbe4786384f25e3,
    0x0fc19dc68b8cd5b5,
    0x240ca1cc77ac9c65,
    0x2de92c6f592b0275,
    0x4a7484aa6ea6e483,
    0x5cb0a9dcbd41fbd4,
    0x76f988da831153b5,
    0x983e5152ee66dfab,
    0xa831c66d2db43210,
    0xb00327c898fb213f,
    0xbf597fc7beef0ee4,
    0xc6e00bf33da88fc2,
    0xd5a79147930aa725,
    0x06ca6351e003826f,
    0x142929670a0e6e70,
    0x27b70a8546d22ffc,
    0x2e1b21385c26c926,
    0x4d2c6dfc5ac42aed,
    0x53380d139d95b3df,
    0x650a73548baf63de,
    0x766a0abb3c77b2a8,
    0x81c2c92e47edaee6,
    0x92722c851482353b,
    0xa2bfe8a14cf10364,
    0xa81a664bbc423001,
    0xc24b8b70d0f89791,
    0xc76c51a30654be30,
    0xd192e819d6ef5218,
    0xd69906245565a910,
    0xf40e35855771202a,
    0x106aa07032bbd1b8,
    0x19a4c116b8d2d0c8,
    0x1e376c085141ab53,
    0x2748774cdf8eeb99,
    0x34b0bcb5e19b48a8,
    0x391c0cb3c5c95a63,
    0x4ed8aa4ae3418acb,
    0x5b9cca4f7763e373,
    0x682e6ff3d6b2b8a3,
    0x748f82ee5defb2fc,
    0x78a5636f43172f60,
    0x84c87814a1f0ab72,
    0x8cc702081a6439ec,
    0x90befffa23631e28,
    0xa4506cebde82bde9,
    0xbef9a3f7b2c67915,
    0xc67178f2e372532b,
    0xca273eceea26619c,
    0xd186b8c721c0c207,
    0xeada7dd6cde0eb1e,
    0xf57d4f7fee6ed178,
    0x06f067aa72176fba,
    0x0a637dc5a2c898a6,
    0x113f9804bef90dae,
    0x1b710b35131c471b,
    0x28db77f523047d84,
    0x32caab7b40c72493,
    0x3c9ebe0a15c9bebc,
    0x431d67c49c100d4c,
    0x4cc5d4becb3e42b6,
    0x597f299cfc657e2a,
    0x5fcb6fab3ad6faec,
    0x6c44198c4a475817,
]);
