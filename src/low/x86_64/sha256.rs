//! Copyright (c) 2006, CRYPTOGAMS by <appro@openssl.org> All rights reserved.
//! SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0-only
//!
//! ====================================================================
//! Written by Andy Polyakov, @dot-asm, initially for the OpenSSL
//! project.
//! ====================================================================
//!
//! sha256/512_block procedure for x86_64.
//!
//! 40% improvement over compiler-generated code on Opteron. On EM64T
//! sha256 was observed to run >80% faster and sha512 - >40%. No magical
//! tricks, just straight implementation... I really wonder why gcc
//! [being armed with inline assembler] fails to generate as fast code.
//! The only thing which is cool about this module is that it's very
//! same instruction sequence used for both SHA-256 and SHA-512. In
//! former case the instructions operate on 32-bit operands, while in
//! latter - on 64-bit ones. All I had to do is to get one flavor right,
//! the other one passed the test right away:-)
//!
//! sha256_block runs in ~1005 cycles on Opteron, which gives you
//! asymptotic performance of 64*1000/1005=63.7MBps times CPU clock
//! frequency in GHz. sha512_block runs in ~1275 cycles, which results
//! in 128*1000/1275=100MBps per GHz. Is there room for improvement?
//! Well, if you compare it to IA-64 implementation, which maintains
//! X[16] in register bank[!], tends to 4 instructions per CPU clock
//! cycle and runs in 1003 cycles, 1275 is very good result for 3-way
//! issue Opteron pipeline and X[16] maintained in memory. So that *if*
//! there is a way to improve it, *then* the only way would be to try to
//! offload X[16] updates to SSE unit, but that would require "deeper"
//! loop unroll, which in turn would naturally cause size blow-up, not
//! to mention increased complexity! And once again, only *if* it's
//! actually possible to noticeably improve overall ILP, instruction
//! level parallelism, on a given CPU implementation in this case.
//!
//! Special note on Intel EM64T. While Opteron CPU exhibits perfect
//! performance ratio of 1.5 between 64- and 32-bit flavors [see above],
//! [currently available] EM64T CPUs apparently are far from it. On the
//! contrary, 64-bit version, sha512_block, is ~30% *slower* than 32-bit
//! sha256_block:-( This is presumably because 64-bit shifts/rotates
//! apparently are not atomic instructions, but implemented in microcode.
//!
//! May 2012.
//!
//! Optimization including one of Pavel Semjanov's ideas, alternative
//! Maj, resulted in >=5% improvement on most CPUs, +20% SHA256 and
//! unfortunately -2% SHA512 on P4 [which nobody should care about
//! that much].
//!
//! June 2012.
//!
//! Add SIMD code paths, see below for improvement coefficients. SSSE3
//! code path was not attempted for SHA512, because improvement is not
//! estimated to be high enough, noticeably less than 9%, to justify
//! the effort, not on pre-AVX processors. [Obviously with exclusion
//! for VIA Nano, but it has SHA512 instruction that is faster and
//! should be used instead.] For reference, corresponding estimated
//! upper limit for improvement for SSSE3 SHA256 is 28%. The fact that
//! higher coefficients are observed on VIA Nano and Bulldozer has more
//! to do with specifics of their architecture [which is topic for
//! separate discussion].
//!
//! November 2012.
//!
//! Add AVX2 code path. Two consecutive input blocks are loaded to
//! 256-bit %ymm registers, with data from first block to least
//! significant 128-bit halves and data from second to most significant.
//! The data is then processed with same SIMD instruction sequence as
//! for AVX, but with %ymm as operands. Side effect is increased stack
//! frame, 448 additional bytes in SHA256 and 1152 in SHA512, and 1.2KB
//! code size increase.
//!
//! March 2014.
//!
//! Add support for Intel SHA Extensions.
//!
//! October 2023.
//!
//! Add support for Intel SHA512 Extension.

#![allow(non_upper_case_globals, unused_macros, unused_imports)]
use crate::low::macros::{Label, Q};

#[inline(never)]
pub fn sha256_block_data_order_shaext(state: &mut [u32; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lshaext_shortcut", 2) ":"),
        Q!("    leaq            " "{K256} + 128 (%rip), %rcx"),
        Q!("    movdqu          " "(%rdi), %xmm1"),
        Q!("    movdqu          " "16 (%rdi), %xmm2"),
        Q!("    movdqa          " "512 -128 (%rcx), %xmm7"),
        Q!("    pshufd          " "$0x1b, %xmm1, %xmm0"),
        Q!("    pshufd          " "$0xb1, %xmm1, %xmm1"),
        Q!("    pshufd          " "$0x1b, %xmm2, %xmm2"),
        Q!("    movdqa          " "%xmm7, %xmm8"),
        Q!("    .byte           " "102, 15, 58, 15, 202, 8"),
        Q!("    punpcklqdq      " "%xmm0, %xmm2"),
        Q!("    jmp             " Label!(".Loop_shaext", 3, After)),
        Q!(Label!(".Loop_shaext", 3) ":"),
        Q!("    movdqu          " "(%rsi), %xmm3"),
        Q!("    movdqu          " "16 (%rsi), %xmm4"),
        Q!("    movdqu          " "32 (%rsi), %xmm5"),
        Q!("    .byte           " "102, 15, 56, 0, 223"),
        Q!("    movdqu          " "48 (%rsi), %xmm6"),
        Q!("    movdqa          " "0 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm3, %xmm0"),
        Q!("    .byte           " "102, 15, 56, 0, 231"),
        Q!("    movdqa          " "%xmm2, %xmm10"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    nop             " ),
        Q!("    movdqa          " "%xmm1, %xmm9"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "32 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm4, %xmm0"),
        Q!("    .byte           " "102, 15, 56, 0, 239"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    leaq            " "64 (%rsi), %rsi"),
        Q!("    .byte           " "15, 56, 204, 220"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "64 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm5, %xmm0"),
        Q!("    .byte           " "102, 15, 56, 0, 247"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm6, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 253, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    .byte           " "15, 56, 204, 229"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "96 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm6, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 222"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm3, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 254, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm4"),
        Q!("    .byte           " "15, 56, 204, 238"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "128 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm3, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 227"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm4, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 251, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm5"),
        Q!("    .byte           " "15, 56, 204, 243"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "160 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm4, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 236"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm5, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 252, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm6"),
        Q!("    .byte           " "15, 56, 204, 220"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "192 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm5, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 245"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm6, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 253, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    .byte           " "15, 56, 204, 229"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "224 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm6, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 222"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm3, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 254, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm4"),
        Q!("    .byte           " "15, 56, 204, 238"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "256 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm3, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 227"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm4, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 251, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm5"),
        Q!("    .byte           " "15, 56, 204, 243"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "288 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm4, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 236"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm5, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 252, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm6"),
        Q!("    .byte           " "15, 56, 204, 220"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "320 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm5, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 245"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm6, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 253, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    .byte           " "15, 56, 204, 229"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "352 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm6, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 222"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm3, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 254, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm4"),
        Q!("    .byte           " "15, 56, 204, 238"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "384 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm3, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 227"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm4, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 251, 4"),
        Q!("    nop             " ),
        Q!("    paddd           " "%xmm7, %xmm5"),
        Q!("    .byte           " "15, 56, 204, 243"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "416 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm4, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 236"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    movdqa          " "%xmm5, %xmm7"),
        Q!("    .byte           " "102, 15, 58, 15, 252, 4"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    paddd           " "%xmm7, %xmm6"),
        Q!("    movdqa          " "448 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm5, %xmm0"),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    .byte           " "15, 56, 205, 245"),
        Q!("    movdqa          " "%xmm8, %xmm7"),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    movdqa          " "480 -128 (%rcx), %xmm0"),
        Q!("    paddd           " "%xmm6, %xmm0"),
        Q!("    nop             " ),
        Q!("    .byte           " "15, 56, 203, 209"),
        Q!("    pshufd          " "$0x0e, %xmm0, %xmm0"),
        Q!("    decq            " "%rdx"),
        Q!("    nop             " ),
        Q!("    .byte           " "15, 56, 203, 202"),
        Q!("    paddd           " "%xmm10, %xmm2"),
        Q!("    paddd           " "%xmm9, %xmm1"),
        Q!("    jnz             " Label!(".Loop_shaext", 3, Before)),
        Q!("    pshufd          " "$0xb1, %xmm2, %xmm2"),
        Q!("    pshufd          " "$0x1b, %xmm1, %xmm7"),
        Q!("    pshufd          " "$0xb1, %xmm1, %xmm1"),
        Q!("    punpckhqdq      " "%xmm2, %xmm1"),
        Q!("    .byte           " "102, 15, 58, 15, 215, 8"),
        Q!("    movdqu          " "%xmm1, (%rdi)"),
        Q!("    movdqu          " "%xmm2, 16 (%rdi)"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 64 => _,
        K256 = sym K256,
        // clobbers
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm10") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        options(att_syntax),
            )
    };
}

#[inline(never)]
pub fn sha256_block_data_order_ssse3(state: &mut [u32; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lssse3_shortcut", 2) ":"),
        Q!("    pushq           " "%rbx"),
        Q!("    pushq           " "%r12"),
        Q!("    pushq           " "%r13"),
        Q!("    pushq           " "%r14"),
        Q!("    pushq           " "%r15"),
        Q!("    shlq            " "$4, %rdx"),
        Q!("    subq            " "$24, %rsp"),
        Q!("    leaq            " "(%rsi, %rdx, 4), %rdx"),
        Q!("    movq            " "%rdi, -64 (%rbp)"),
        Q!("    movq            " "%rdx, -48 (%rbp)"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    movl            " "0 (%rdi), %eax"),
        Q!("    andq            " "$-64, %rsp"),
        Q!("    movl            " "4 (%rdi), %ebx"),
        Q!("    movl            " "8 (%rdi), %ecx"),
        Q!("    movl            " "12 (%rdi), %edx"),
        Q!("    movl            " "16 (%rdi), %r8d"),
        Q!("    movl            " "20 (%rdi), %r9d"),
        Q!("    movl            " "24 (%rdi), %r10d"),
        Q!("    movl            " "28 (%rdi), %r11d"),
        Q!("    jmp             " Label!(".Lloop_ssse3", 3, After)),
        Q!(Label!(".Lloop_ssse3", 3) ":"),
        Q!("    movdqa          " "{K256} + 512 (%rip), %xmm7"),
        Q!("    movq            " "%rsi, -56 (%rbp)"),
        Q!("    movdqu          " "0 (%rsi), %xmm0"),
        Q!("    movdqu          " "16 (%rsi), %xmm1"),
        Q!("    movdqu          " "32 (%rsi), %xmm2"),
        Q!("    .byte           " "102, 15, 56, 0, 199"),
        Q!("    movdqu          " "48 (%rsi), %xmm3"),
        Q!("    leaq            " "{K256} (%rip), %rsi"),
        Q!("    .byte           " "102, 15, 56, 0, 207"),
        Q!("    movdqa          " "0 (%rsi), %xmm4"),
        Q!("    movdqa          " "32 (%rsi), %xmm5"),
        Q!("    .byte           " "102, 15, 56, 0, 215"),
        Q!("    paddd           " "%xmm0, %xmm4"),
        Q!("    movdqa          " "64 (%rsi), %xmm6"),
        Q!("    .byte           " "102, 15, 56, 0, 223"),
        Q!("    movdqa          " "96 (%rsi), %xmm7"),
        Q!("    paddd           " "%xmm1, %xmm5"),
        Q!("    paddd           " "%xmm2, %xmm6"),
        Q!("    paddd           " "%xmm3, %xmm7"),
        Q!("    movdqa          " "%xmm4, 0 (%rsp)"),
        Q!("    movl            " "%eax, %r14d"),
        Q!("    movdqa          " "%xmm5, 16 (%rsp)"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    movdqa          " "%xmm6, 32 (%rsp)"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    movdqa          " "%xmm7, 48 (%rsp)"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    jmp             " Label!(".Lssse3_00_47", 4, After)),
        Q!(Label!(".Lssse3_00_47", 4) ":"),
        Q!("    subq            " "$-128, %rsi"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movdqa          " "%xmm1, %xmm4"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    movdqa          " "%xmm3, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    .byte           " "102, 15, 58, 15, 224, 4"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    .byte           " "102, 15, 58, 15, 250, 4"),
        Q!("    addl            " "0 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm4, %xmm5"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    movdqa          " "%xmm4, %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    psrld           " "$3, %xmm4"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    paddd           " "%xmm7, %xmm0"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    psrld           " "$7, %xmm6"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    pshufd          " "$250, %xmm3, %xmm7"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    pslld           " "$14, %xmm5"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    psrld           " "$11, %xmm6"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    pslld           " "$11, %xmm5"),
        Q!("    addl            " "4 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    paddd           " "%xmm4, %xmm0"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    pshufd          " "$128, %xmm7, %xmm7"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "8 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    psrldq          " "$8, %xmm7"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    paddd           " "%xmm7, %xmm0"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    pshufd          " "$80, %xmm0, %xmm7"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "12 (%rsp), %r8d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    pshufd          " "$8, %xmm7, %xmm7"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    movdqa          " "0 (%rsi), %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    pslldq          " "$8, %xmm7"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    paddd           " "%xmm7, %xmm0"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    paddd           " "%xmm0, %xmm6"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    movdqa          " "%xmm6, 0 (%rsp)"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movdqa          " "%xmm2, %xmm4"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    movdqa          " "%xmm0, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    .byte           " "102, 15, 58, 15, 225, 4"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    .byte           " "102, 15, 58, 15, 251, 4"),
        Q!("    addl            " "16 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm4, %xmm5"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    movdqa          " "%xmm4, %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    psrld           " "$3, %xmm4"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    paddd           " "%xmm7, %xmm1"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    psrld           " "$7, %xmm6"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    pshufd          " "$250, %xmm0, %xmm7"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    pslld           " "$14, %xmm5"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    psrld           " "$11, %xmm6"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    pslld           " "$11, %xmm5"),
        Q!("    addl            " "20 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    paddd           " "%xmm4, %xmm1"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    pshufd          " "$128, %xmm7, %xmm7"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "24 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    psrldq          " "$8, %xmm7"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    paddd           " "%xmm7, %xmm1"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    pshufd          " "$80, %xmm1, %xmm7"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "28 (%rsp), %eax"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    pshufd          " "$8, %xmm7, %xmm7"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    movdqa          " "32 (%rsi), %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    pslldq          " "$8, %xmm7"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    paddd           " "%xmm7, %xmm1"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    paddd           " "%xmm1, %xmm6"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    movdqa          " "%xmm6, 16 (%rsp)"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movdqa          " "%xmm3, %xmm4"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    movdqa          " "%xmm1, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    .byte           " "102, 15, 58, 15, 226, 4"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    .byte           " "102, 15, 58, 15, 248, 4"),
        Q!("    addl            " "32 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm4, %xmm5"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    movdqa          " "%xmm4, %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    psrld           " "$3, %xmm4"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    paddd           " "%xmm7, %xmm2"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    psrld           " "$7, %xmm6"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    pshufd          " "$250, %xmm1, %xmm7"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    pslld           " "$14, %xmm5"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    psrld           " "$11, %xmm6"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    pslld           " "$11, %xmm5"),
        Q!("    addl            " "36 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    paddd           " "%xmm4, %xmm2"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    pshufd          " "$128, %xmm7, %xmm7"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "40 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    psrldq          " "$8, %xmm7"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    paddd           " "%xmm7, %xmm2"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    pshufd          " "$80, %xmm2, %xmm7"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "44 (%rsp), %r8d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    pshufd          " "$8, %xmm7, %xmm7"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    movdqa          " "64 (%rsi), %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    pslldq          " "$8, %xmm7"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    paddd           " "%xmm7, %xmm2"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    paddd           " "%xmm2, %xmm6"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    movdqa          " "%xmm6, 32 (%rsp)"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movdqa          " "%xmm0, %xmm4"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    movdqa          " "%xmm2, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    .byte           " "102, 15, 58, 15, 227, 4"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    .byte           " "102, 15, 58, 15, 249, 4"),
        Q!("    addl            " "48 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm4, %xmm5"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    movdqa          " "%xmm4, %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    psrld           " "$3, %xmm4"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    psrld           " "$7, %xmm6"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    pshufd          " "$250, %xmm2, %xmm7"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    pslld           " "$14, %xmm5"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    psrld           " "$11, %xmm6"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    pslld           " "$11, %xmm5"),
        Q!("    addl            " "52 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    pxor            " "%xmm6, %xmm4"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    pxor            " "%xmm5, %xmm4"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    paddd           " "%xmm4, %xmm3"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    pshufd          " "$128, %xmm7, %xmm7"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "56 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    psrldq          " "$8, %xmm7"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    pshufd          " "$80, %xmm3, %xmm7"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    movdqa          " "%xmm7, %xmm6"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    psrld           " "$10, %xmm7"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    psrlq           " "$17, %xmm6"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    psrlq           " "$2, %xmm6"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "60 (%rsp), %eax"),
        Q!("    pxor            " "%xmm6, %xmm7"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    pshufd          " "$8, %xmm7, %xmm7"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    movdqa          " "96 (%rsi), %xmm6"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    pslldq          " "$8, %xmm7"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    paddd           " "%xmm7, %xmm3"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    paddd           " "%xmm3, %xmm6"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    movdqa          " "%xmm6, 48 (%rsp)"),
        Q!("    cmpb            " "$0, 131 (%rsi)"),
        Q!("    jne             " Label!(".Lssse3_00_47", 4, Before)),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "0 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    addl            " "4 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "8 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "12 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "16 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    addl            " "20 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "24 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "28 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "32 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    addl            " "36 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "40 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "44 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "48 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    addl            " "52 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "56 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    rorl            " "$14, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    rorl            " "$9, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$5, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "60 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    rorl            " "$11, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    rorl            " "$6, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    rorl            " "$2, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movq            " "-56 (%rbp), %rsi"),
        Q!("    addl            " "0 (%rdi), %eax"),
        Q!("    addl            " "4 (%rdi), %ebx"),
        Q!("    addl            " "8 (%rdi), %ecx"),
        Q!("    addl            " "12 (%rdi), %edx"),
        Q!("    addl            " "16 (%rdi), %r8d"),
        Q!("    addl            " "20 (%rdi), %r9d"),
        Q!("    addl            " "24 (%rdi), %r10d"),
        Q!("    addl            " "28 (%rdi), %r11d"),
        Q!("    leaq            " "64 (%rsi), %rsi"),
        Q!("    cmpq            " "-48 (%rbp), %rsi"),
        Q!("    movl            " "%eax, 0 (%rdi)"),
        Q!("    movl            " "%ebx, 4 (%rdi)"),
        Q!("    movl            " "%ecx, 8 (%rdi)"),
        Q!("    movl            " "%edx, 12 (%rdi)"),
        Q!("    movl            " "%r8d, 16 (%rdi)"),
        Q!("    movl            " "%r9d, 20 (%rdi)"),
        Q!("    movl            " "%r10d, 24 (%rdi)"),
        Q!("    movl            " "%r11d, 28 (%rdi)"),
        Q!("    jb              " Label!(".Lloop_ssse3", 3, Before)),
        Q!("    movq            " "-40 (%rbp), %r15"),
        Q!("    movq            " "-32 (%rbp), %r14"),
        Q!("    movq            " "-24 (%rbp), %r13"),
        Q!("    movq            " "-16 (%rbp), %r12"),
        Q!("    movq            " "-8 (%rbp), %rbx"),
        Q!("    movq            " "%rbp, %rsp"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 64 => _,
        K256 = sym K256,
        // clobbers
        out("r12") _,
        out("r13") _,
        out("r14") _,
        out("r15") _,
        out("rax") _,
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        options(att_syntax),
            )
    };
}

#[inline(never)]
pub fn sha256_block_data_order_avx(state: &mut [u32; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lavx_shortcut", 2) ":"),
        Q!("    pushq           " "%rbx"),
        Q!("    pushq           " "%r12"),
        Q!("    pushq           " "%r13"),
        Q!("    pushq           " "%r14"),
        Q!("    pushq           " "%r15"),
        Q!("    shlq            " "$4, %rdx"),
        Q!("    subq            " "$24, %rsp"),
        Q!("    leaq            " "(%rsi, %rdx, 4), %rdx"),
        Q!("    movq            " "%rdi, -64 (%rbp)"),
        Q!("    movq            " "%rdx, -48 (%rbp)"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    vzeroupper      " ),
        Q!("    andq            " "$-64, %rsp"),
        Q!("    movl            " "0 (%rdi), %eax"),
        Q!("    movl            " "4 (%rdi), %ebx"),
        Q!("    movl            " "8 (%rdi), %ecx"),
        Q!("    movl            " "12 (%rdi), %edx"),
        Q!("    movl            " "16 (%rdi), %r8d"),
        Q!("    movl            " "20 (%rdi), %r9d"),
        Q!("    movl            " "24 (%rdi), %r10d"),
        Q!("    movl            " "28 (%rdi), %r11d"),
        Q!("    vmovdqa         " "{K256} + 512 + 32 (%rip), %xmm8"),
        Q!("    vmovdqa         " "{K256} + 512 + 64 (%rip), %xmm9"),
        Q!("    jmp             " Label!(".Lloop_avx", 3, After)),
        Q!(Label!(".Lloop_avx", 3) ":"),
        Q!("    vmovdqa         " "{K256} + 512 (%rip), %xmm7"),
        Q!("    movq            " "%rsi, -56 (%rbp)"),
        Q!("    vmovdqu         " "0 (%rsi), %xmm0"),
        Q!("    vmovdqu         " "16 (%rsi), %xmm1"),
        Q!("    vmovdqu         " "32 (%rsi), %xmm2"),
        Q!("    vmovdqu         " "48 (%rsi), %xmm3"),
        Q!("    vpshufb         " "%xmm7, %xmm0, %xmm0"),
        Q!("    leaq            " "{K256} (%rip), %rsi"),
        Q!("    vpshufb         " "%xmm7, %xmm1, %xmm1"),
        Q!("    vpshufb         " "%xmm7, %xmm2, %xmm2"),
        Q!("    vpaddd          " "0 (%rsi), %xmm0, %xmm4"),
        Q!("    vpshufb         " "%xmm7, %xmm3, %xmm3"),
        Q!("    vpaddd          " "32 (%rsi), %xmm1, %xmm5"),
        Q!("    vpaddd          " "64 (%rsi), %xmm2, %xmm6"),
        Q!("    vpaddd          " "96 (%rsi), %xmm3, %xmm7"),
        Q!("    vmovdqa         " "%xmm4, 0 (%rsp)"),
        Q!("    movl            " "%eax, %r14d"),
        Q!("    vmovdqa         " "%xmm5, 16 (%rsp)"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    vmovdqa         " "%xmm6, 32 (%rsp)"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    vmovdqa         " "%xmm7, 48 (%rsp)"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    jmp             " Label!(".Lavx_00_47", 4, After)),
        Q!(Label!(".Lavx_00_47", 4) ":"),
        Q!("    subq            " "$-128, %rsi"),
        Q!("    vpalignr        " "$4, %xmm0, %xmm1, %xmm4"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    vpalignr        " "$4, %xmm2, %xmm3, %xmm7"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    vpsrld          " "$7, %xmm4, %xmm6"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    vpaddd          " "%xmm7, %xmm0, %xmm0"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "0 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    vpsrld          " "$3, %xmm4, %xmm7"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    vpslld          " "$14, %xmm4, %xmm5"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    vpxor           " "%xmm6, %xmm7, %xmm4"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    vpshufd         " "$250, %xmm3, %xmm7"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    vpsrld          " "$11, %xmm6, %xmm6"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    vpslld          " "$11, %xmm5, %xmm5"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm6, %xmm4, %xmm4"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    addl            " "4 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    vpaddd          " "%xmm4, %xmm0, %xmm0"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    vpshufb         " "%xmm8, %xmm6, %xmm6"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    vpaddd          " "%xmm6, %xmm0, %xmm0"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "8 (%rsp), %r9d"),
        Q!("    vpshufd         " "$80, %xmm0, %xmm7"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    vpshufb         " "%xmm9, %xmm6, %xmm6"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    vpaddd          " "%xmm6, %xmm0, %xmm0"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    vpaddd          " "0 (%rsi), %xmm0, %xmm6"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "12 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    vmovdqa         " "%xmm6, 0 (%rsp)"),
        Q!("    vpalignr        " "$4, %xmm1, %xmm2, %xmm4"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    vpalignr        " "$4, %xmm3, %xmm0, %xmm7"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    vpsrld          " "$7, %xmm4, %xmm6"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    vpaddd          " "%xmm7, %xmm1, %xmm1"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "16 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    vpsrld          " "$3, %xmm4, %xmm7"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    vpslld          " "$14, %xmm4, %xmm5"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    vpxor           " "%xmm6, %xmm7, %xmm4"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    vpshufd         " "$250, %xmm0, %xmm7"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    vpsrld          " "$11, %xmm6, %xmm6"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    vpslld          " "$11, %xmm5, %xmm5"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm6, %xmm4, %xmm4"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    addl            " "20 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    vpaddd          " "%xmm4, %xmm1, %xmm1"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    vpshufb         " "%xmm8, %xmm6, %xmm6"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    vpaddd          " "%xmm6, %xmm1, %xmm1"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "24 (%rsp), %ebx"),
        Q!("    vpshufd         " "$80, %xmm1, %xmm7"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    vpshufb         " "%xmm9, %xmm6, %xmm6"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    vpaddd          " "%xmm6, %xmm1, %xmm1"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    vpaddd          " "32 (%rsi), %xmm1, %xmm6"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "28 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    vmovdqa         " "%xmm6, 16 (%rsp)"),
        Q!("    vpalignr        " "$4, %xmm2, %xmm3, %xmm4"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    vpalignr        " "$4, %xmm0, %xmm1, %xmm7"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    vpsrld          " "$7, %xmm4, %xmm6"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    vpaddd          " "%xmm7, %xmm2, %xmm2"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "32 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    vpsrld          " "$3, %xmm4, %xmm7"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    vpslld          " "$14, %xmm4, %xmm5"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    vpxor           " "%xmm6, %xmm7, %xmm4"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    vpshufd         " "$250, %xmm1, %xmm7"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    vpsrld          " "$11, %xmm6, %xmm6"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    vpslld          " "$11, %xmm5, %xmm5"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm6, %xmm4, %xmm4"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    addl            " "36 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    vpaddd          " "%xmm4, %xmm2, %xmm2"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    vpshufb         " "%xmm8, %xmm6, %xmm6"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    vpaddd          " "%xmm6, %xmm2, %xmm2"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "40 (%rsp), %r9d"),
        Q!("    vpshufd         " "$80, %xmm2, %xmm7"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    vpshufb         " "%xmm9, %xmm6, %xmm6"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    vpaddd          " "%xmm6, %xmm2, %xmm2"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    vpaddd          " "64 (%rsi), %xmm2, %xmm6"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "44 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    vmovdqa         " "%xmm6, 32 (%rsp)"),
        Q!("    vpalignr        " "$4, %xmm3, %xmm0, %xmm4"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    vpalignr        " "$4, %xmm1, %xmm2, %xmm7"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    vpsrld          " "$7, %xmm4, %xmm6"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    vpaddd          " "%xmm7, %xmm3, %xmm3"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "48 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    vpsrld          " "$3, %xmm4, %xmm7"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    vpslld          " "$14, %xmm4, %xmm5"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    vpxor           " "%xmm6, %xmm7, %xmm4"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    vpshufd         " "$250, %xmm2, %xmm7"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    vpsrld          " "$11, %xmm6, %xmm6"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    vpslld          " "$11, %xmm5, %xmm5"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    vpxor           " "%xmm6, %xmm4, %xmm4"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    addl            " "52 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    vpxor           " "%xmm5, %xmm4, %xmm4"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    vpaddd          " "%xmm4, %xmm3, %xmm3"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    vpshufb         " "%xmm8, %xmm6, %xmm6"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    vpaddd          " "%xmm6, %xmm3, %xmm3"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "56 (%rsp), %ebx"),
        Q!("    vpshufd         " "$80, %xmm3, %xmm7"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    vpsrld          " "$10, %xmm7, %xmm6"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    vpsrlq          " "$17, %xmm7, %xmm7"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    vpsrlq          " "$2, %xmm7, %xmm7"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    vpxor           " "%xmm7, %xmm6, %xmm6"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    vpshufb         " "%xmm9, %xmm6, %xmm6"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    vpaddd          " "%xmm6, %xmm3, %xmm3"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    vpaddd          " "96 (%rsi), %xmm3, %xmm6"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "60 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    vmovdqa         " "%xmm6, 48 (%rsp)"),
        Q!("    cmpb            " "$0, 131 (%rsi)"),
        Q!("    jne             " Label!(".Lavx_00_47", 4, Before)),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "0 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    addl            " "4 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "8 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "12 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "16 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    addl            " "20 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "24 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "28 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    xorl            " "%r8d, %r13d"),
        Q!("    addl            " "32 (%rsp), %r11d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    xorl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    addl            " "%r12d, %r11d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%eax, %r14d"),
        Q!("    addl            " "%r13d, %r11d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r11d, %edx"),
        Q!("    addl            " "%edi, %r11d"),
        Q!("    movl            " "%edx, %r13d"),
        Q!("    addl            " "%r11d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    xorl            " "%edx, %r13d"),
        Q!("    addl            " "36 (%rsp), %r10d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    xorl            " "%r9d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    addl            " "%r12d, %r10d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r11d, %r14d"),
        Q!("    addl            " "%r13d, %r10d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r10d, %ecx"),
        Q!("    addl            " "%r15d, %r10d"),
        Q!("    movl            " "%ecx, %r13d"),
        Q!("    addl            " "%r10d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    xorl            " "%ecx, %r13d"),
        Q!("    addl            " "40 (%rsp), %r9d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r8d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    addl            " "%r12d, %r9d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r10d, %r14d"),
        Q!("    addl            " "%r13d, %r9d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r9d, %ebx"),
        Q!("    addl            " "%edi, %r9d"),
        Q!("    movl            " "%ebx, %r13d"),
        Q!("    addl            " "%r9d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    xorl            " "%ebx, %r13d"),
        Q!("    addl            " "44 (%rsp), %r8d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    xorl            " "%edx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    addl            " "%r12d, %r8d"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r9d, %r14d"),
        Q!("    addl            " "%r13d, %r8d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%r8d, %eax"),
        Q!("    addl            " "%r15d, %r8d"),
        Q!("    movl            " "%eax, %r13d"),
        Q!("    addl            " "%r8d, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    xorl            " "%eax, %r13d"),
        Q!("    addl            " "48 (%rsp), %edx"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    xorl            " "%ecx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    addl            " "%r12d, %edx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r8d, %r14d"),
        Q!("    addl            " "%r13d, %edx"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%edx, %r11d"),
        Q!("    addl            " "%edi, %edx"),
        Q!("    movl            " "%r11d, %r13d"),
        Q!("    addl            " "%edx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    xorl            " "%r11d, %r13d"),
        Q!("    addl            " "52 (%rsp), %ecx"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    xorl            " "%ebx, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    addl            " "%r12d, %ecx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%edx, %r14d"),
        Q!("    addl            " "%r13d, %ecx"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ecx, %r10d"),
        Q!("    addl            " "%r15d, %ecx"),
        Q!("    movl            " "%r10d, %r13d"),
        Q!("    addl            " "%ecx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    xorl            " "%r10d, %r13d"),
        Q!("    addl            " "56 (%rsp), %ebx"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    xorl            " "%eax, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    addl            " "%r12d, %ebx"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%ecx, %r14d"),
        Q!("    addl            " "%r13d, %ebx"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%ebx, %r9d"),
        Q!("    addl            " "%edi, %ebx"),
        Q!("    movl            " "%r9d, %r13d"),
        Q!("    addl            " "%ebx, %r14d"),
        Q!("    shrdl           " "$14, %r13d, %r13d"),
        Q!("    movl            " "%r14d, %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    shrdl           " "$9, %r14d, %r14d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$5, %r13d, %r13d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    xorl            " "%r9d, %r13d"),
        Q!("    addl            " "60 (%rsp), %eax"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%r11d, %r12d"),
        Q!("    shrdl           " "$11, %r14d, %r14d"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    addl            " "%r12d, %eax"),
        Q!("    shrdl           " "$6, %r13d, %r13d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%ebx, %r14d"),
        Q!("    addl            " "%r13d, %eax"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    shrdl           " "$2, %r14d, %r14d"),
        Q!("    addl            " "%eax, %r8d"),
        Q!("    addl            " "%r15d, %eax"),
        Q!("    movl            " "%r8d, %r13d"),
        Q!("    addl            " "%eax, %r14d"),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    movl            " "%r14d, %eax"),
        Q!("    movq            " "-56 (%rbp), %rsi"),
        Q!("    addl            " "0 (%rdi), %eax"),
        Q!("    addl            " "4 (%rdi), %ebx"),
        Q!("    addl            " "8 (%rdi), %ecx"),
        Q!("    addl            " "12 (%rdi), %edx"),
        Q!("    addl            " "16 (%rdi), %r8d"),
        Q!("    addl            " "20 (%rdi), %r9d"),
        Q!("    addl            " "24 (%rdi), %r10d"),
        Q!("    addl            " "28 (%rdi), %r11d"),
        Q!("    leaq            " "64 (%rsi), %rsi"),
        Q!("    cmpq            " "-48 (%rbp), %rsi"),
        Q!("    movl            " "%eax, 0 (%rdi)"),
        Q!("    movl            " "%ebx, 4 (%rdi)"),
        Q!("    movl            " "%ecx, 8 (%rdi)"),
        Q!("    movl            " "%edx, 12 (%rdi)"),
        Q!("    movl            " "%r8d, 16 (%rdi)"),
        Q!("    movl            " "%r9d, 20 (%rdi)"),
        Q!("    movl            " "%r10d, 24 (%rdi)"),
        Q!("    movl            " "%r11d, 28 (%rdi)"),
        Q!("    jb              " Label!(".Lloop_avx", 3, Before)),
        Q!("    vzeroupper      " ),
        Q!("    movq            " "-40 (%rbp), %r15"),
        Q!("    movq            " "-32 (%rbp), %r14"),
        Q!("    movq            " "-24 (%rbp), %r13"),
        Q!("    movq            " "-16 (%rbp), %r12"),
        Q!("    movq            " "-8 (%rbp), %rbx"),
        Q!("    movq            " "%rbp, %rsp"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 64 => _,
        K256 = sym K256,
        // clobbers
        out("r12") _,
        out("r13") _,
        out("r14") _,
        out("r15") _,
        out("rax") _,
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        options(att_syntax),
            )
    };
}

#[inline(never)]
pub fn sha256_block_data_order_avx2(state: &mut [u32; 8], blocks: &[u8]) {
    unsafe {
        core::arch::asm!(

        Q!("    .byte           " "0xf3, 0x0f, 0x1e, 0xfa"),
        Q!("    pushq           " "%rbp"),
        Q!("    movq            " "%rsp, %rbp"),
        Q!(Label!(".Lavx2_shortcut", 2) ":"),
        Q!("    pushq           " "%rbx"),
        Q!("    pushq           " "%r12"),
        Q!("    pushq           " "%r13"),
        Q!("    pushq           " "%r14"),
        Q!("    pushq           " "%r15"),
        Q!("    shlq            " "$4, %rdx"),
        Q!("    subq            " "$24, %rsp"),
        Q!("    leaq            " "(%rsi, %rdx, 4), %rdx"),
        Q!("    movq            " "%rdi, -64 (%rbp)"),
        Q!("    movq            " "%rdx, -48 (%rbp)"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    vzeroupper      " ),
        Q!("    andq            " "$-64, %rsp"),
        Q!("    subq            " "$-64, %rsi"),
        Q!("    movl            " "0 (%rdi), %eax"),
        Q!("    movq            " "%rsi, %r12"),
        Q!("    movl            " "4 (%rdi), %ebx"),
        Q!("    cmpq            " "%rdx, %rsi"),
        Q!("    movl            " "8 (%rdi), %ecx"),
        Q!("    cmoveq          " "%rsp, %r12"),
        Q!("    movl            " "12 (%rdi), %edx"),
        Q!("    movl            " "16 (%rdi), %r8d"),
        Q!("    movl            " "20 (%rdi), %r9d"),
        Q!("    movl            " "24 (%rdi), %r10d"),
        Q!("    movl            " "28 (%rdi), %r11d"),
        Q!("    vmovdqa         " "{K256} + 512 + 32 (%rip), %ymm8"),
        Q!("    vmovdqa         " "{K256} + 512 + 64 (%rip), %ymm9"),
        Q!("    jmp             " Label!(".Loop_avx2", 3, After)),
        Q!(Label!(".Loop_avx2", 3) ":"),
        Q!("    vmovdqa         " "{K256} + 512 (%rip), %ymm7"),
        Q!("    movq            " "%rsi, -56 (%rbp)"),
        Q!("    vmovdqu         " "-64 + 0 (%rsi), %xmm0"),
        Q!("    vmovdqu         " "-64 + 16 (%rsi), %xmm1"),
        Q!("    vmovdqu         " "-64 + 32 (%rsi), %xmm2"),
        Q!("    vmovdqu         " "-64 + 48 (%rsi), %xmm3"),
        Q!("    leaq            " "{K256} (%rip), %rsi"),
        Q!("    vinserti128     " "$1, (%r12), %ymm0, %ymm0"),
        Q!("    vinserti128     " "$1, 16 (%r12), %ymm1, %ymm1"),
        Q!("    vpshufb         " "%ymm7, %ymm0, %ymm0"),
        Q!("    vinserti128     " "$1, 32 (%r12), %ymm2, %ymm2"),
        Q!("    vpshufb         " "%ymm7, %ymm1, %ymm1"),
        Q!("    vinserti128     " "$1, 48 (%r12), %ymm3, %ymm3"),
        Q!("    vpshufb         " "%ymm7, %ymm2, %ymm2"),
        Q!("    vpaddd          " "0 (%rsi), %ymm0, %ymm4"),
        Q!("    vpshufb         " "%ymm7, %ymm3, %ymm3"),
        Q!("    vpaddd          " "32 (%rsi), %ymm1, %ymm5"),
        Q!("    vpaddd          " "64 (%rsi), %ymm2, %ymm6"),
        Q!("    vpaddd          " "96 (%rsi), %ymm3, %ymm7"),
        Q!("    vmovdqa         " "%ymm4, 0 (%rsp)"),
        Q!("    xorl            " "%r14d, %r14d"),
        Q!("    vmovdqa         " "%ymm5, 32 (%rsp)"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    vmovdqa         " "%ymm6, 0 (%rsp)"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    vmovdqa         " "%ymm7, 32 (%rsp)"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    subq            " "$-32 * 4, %rsi"),
        Q!("    jmp             " Label!(".Lavx2_00_47", 4, After)),
        Q!(Label!(".Lavx2_00_47", 4) ":"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    vpalignr        " "$4, %ymm0, %ymm1, %ymm4"),
        Q!("    addl            " "0 + 128 (%rsp), %r11d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    rorxl           " "$25, %r8d, %r13d"),
        Q!("    vpalignr        " "$4, %ymm2, %ymm3, %ymm7"),
        Q!("    rorxl           " "$11, %r8d, %r15d"),
        Q!("    leal            " "(%rax, %r14, 1), %eax"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    vpsrld          " "$7, %ymm4, %ymm6"),
        Q!("    andnl           " "%r10d, %r8d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r8d, %r14d"),
        Q!("    vpaddd          " "%ymm7, %ymm0, %ymm0"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    vpsrld          " "$3, %ymm4, %ymm7"),
        Q!("    rorxl           " "$22, %eax, %r12d"),
        Q!("    leal            " "(%r11, %r13, 1), %r11d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    vpslld          " "$14, %ymm4, %ymm5"),
        Q!("    rorxl           " "$13, %eax, %r14d"),
        Q!("    rorxl           " "$2, %eax, %r13d"),
        Q!("    leal            " "(%rdx, %r11, 1), %edx"),
        Q!("    vpxor           " "%ymm6, %ymm7, %ymm4"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    vpshufd         " "$250, %ymm3, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r11, %rdi, 1), %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    vpsrld          " "$11, %ymm6, %ymm6"),
        Q!("    addl            " "4 + 128 (%rsp), %r10d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    rorxl           " "$25, %edx, %r13d"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$11, %edx, %edi"),
        Q!("    leal            " "(%r11, %r14, 1), %r11d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    vpslld          " "$11, %ymm5, %ymm5"),
        Q!("    andnl           " "%r9d, %edx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %edx, %r14d"),
        Q!("    vpxor           " "%ymm6, %ymm4, %ymm4"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    rorxl           " "$22, %r11d, %r12d"),
        Q!("    leal            " "(%r10, %r13, 1), %r10d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$13, %r11d, %r14d"),
        Q!("    rorxl           " "$2, %r11d, %r13d"),
        Q!("    leal            " "(%rcx, %r10, 1), %ecx"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    vpaddd          " "%ymm4, %ymm0, %ymm0"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r10, %r15, 1), %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "8 + 128 (%rsp), %r9d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    rorxl           " "$25, %ecx, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %ecx, %r15d"),
        Q!("    leal            " "(%r10, %r14, 1), %r10d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%r8d, %ecx, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %ecx, %r14d"),
        Q!("    vpshufb         " "%ymm8, %ymm6, %ymm6"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    vpaddd          " "%ymm6, %ymm0, %ymm0"),
        Q!("    rorxl           " "$22, %r10d, %r12d"),
        Q!("    leal            " "(%r9, %r13, 1), %r9d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    vpshufd         " "$80, %ymm0, %ymm7"),
        Q!("    rorxl           " "$13, %r10d, %r14d"),
        Q!("    rorxl           " "$2, %r10d, %r13d"),
        Q!("    leal            " "(%rbx, %r9, 1), %ebx"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r9, %rdi, 1), %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "12 + 128 (%rsp), %r8d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    rorxl           " "$25, %ebx, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %ebx, %edi"),
        Q!("    leal            " "(%r9, %r14, 1), %r9d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%edx, %ebx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %ebx, %r14d"),
        Q!("    vpshufb         " "%ymm9, %ymm6, %ymm6"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    vpaddd          " "%ymm6, %ymm0, %ymm0"),
        Q!("    rorxl           " "$22, %r9d, %r12d"),
        Q!("    leal            " "(%r8, %r13, 1), %r8d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    vpaddd          " "0 (%rsi), %ymm0, %ymm6"),
        Q!("    rorxl           " "$13, %r9d, %r14d"),
        Q!("    rorxl           " "$2, %r9d, %r13d"),
        Q!("    leal            " "(%rax, %r8, 1), %eax"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r8, %r15, 1), %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    vmovdqa         " "%ymm6, 0 (%rsp)"),
        Q!("    vpalignr        " "$4, %ymm1, %ymm2, %ymm4"),
        Q!("    addl            " "32 + 128 (%rsp), %edx"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    rorxl           " "$25, %eax, %r13d"),
        Q!("    vpalignr        " "$4, %ymm3, %ymm0, %ymm7"),
        Q!("    rorxl           " "$11, %eax, %r15d"),
        Q!("    leal            " "(%r8, %r14, 1), %r8d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    vpsrld          " "$7, %ymm4, %ymm6"),
        Q!("    andnl           " "%ecx, %eax, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %eax, %r14d"),
        Q!("    vpaddd          " "%ymm7, %ymm1, %ymm1"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    vpsrld          " "$3, %ymm4, %ymm7"),
        Q!("    rorxl           " "$22, %r8d, %r12d"),
        Q!("    leal            " "(%rdx, %r13, 1), %edx"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    vpslld          " "$14, %ymm4, %ymm5"),
        Q!("    rorxl           " "$13, %r8d, %r14d"),
        Q!("    rorxl           " "$2, %r8d, %r13d"),
        Q!("    leal            " "(%r11, %rdx, 1), %r11d"),
        Q!("    vpxor           " "%ymm6, %ymm7, %ymm4"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    vpshufd         " "$250, %ymm0, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rdx, %rdi, 1), %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    vpsrld          " "$11, %ymm6, %ymm6"),
        Q!("    addl            " "36 + 128 (%rsp), %ecx"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    rorxl           " "$25, %r11d, %r13d"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$11, %r11d, %edi"),
        Q!("    leal            " "(%rdx, %r14, 1), %edx"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    vpslld          " "$11, %ymm5, %ymm5"),
        Q!("    andnl           " "%ebx, %r11d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r11d, %r14d"),
        Q!("    vpxor           " "%ymm6, %ymm4, %ymm4"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    rorxl           " "$22, %edx, %r12d"),
        Q!("    leal            " "(%rcx, %r13, 1), %ecx"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$13, %edx, %r14d"),
        Q!("    rorxl           " "$2, %edx, %r13d"),
        Q!("    leal            " "(%r10, %rcx, 1), %r10d"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    vpaddd          " "%ymm4, %ymm1, %ymm1"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rcx, %r15, 1), %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "40 + 128 (%rsp), %ebx"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    rorxl           " "$25, %r10d, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %r10d, %r15d"),
        Q!("    leal            " "(%rcx, %r14, 1), %ecx"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%eax, %r10d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r10d, %r14d"),
        Q!("    vpshufb         " "%ymm8, %ymm6, %ymm6"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    vpaddd          " "%ymm6, %ymm1, %ymm1"),
        Q!("    rorxl           " "$22, %ecx, %r12d"),
        Q!("    leal            " "(%rbx, %r13, 1), %ebx"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    vpshufd         " "$80, %ymm1, %ymm7"),
        Q!("    rorxl           " "$13, %ecx, %r14d"),
        Q!("    rorxl           " "$2, %ecx, %r13d"),
        Q!("    leal            " "(%r9, %rbx, 1), %r9d"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rbx, %rdi, 1), %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "44 + 128 (%rsp), %eax"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    rorxl           " "$25, %r9d, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %r9d, %edi"),
        Q!("    leal            " "(%rbx, %r14, 1), %ebx"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%r11d, %r9d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r9d, %r14d"),
        Q!("    vpshufb         " "%ymm9, %ymm6, %ymm6"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    vpaddd          " "%ymm6, %ymm1, %ymm1"),
        Q!("    rorxl           " "$22, %ebx, %r12d"),
        Q!("    leal            " "(%rax, %r13, 1), %eax"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    vpaddd          " "32 (%rsi), %ymm1, %ymm6"),
        Q!("    rorxl           " "$13, %ebx, %r14d"),
        Q!("    rorxl           " "$2, %ebx, %r13d"),
        Q!("    leal            " "(%r8, %rax, 1), %r8d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rax, %r15, 1), %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    vmovdqa         " "%ymm6, 32 (%rsp)"),
        Q!("    leaq            " "-64 (%rsp), %rsp"),
        Q!("    vpalignr        " "$4, %ymm2, %ymm3, %ymm4"),
        Q!("    addl            " "0 + 128 (%rsp), %r11d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    rorxl           " "$25, %r8d, %r13d"),
        Q!("    vpalignr        " "$4, %ymm0, %ymm1, %ymm7"),
        Q!("    rorxl           " "$11, %r8d, %r15d"),
        Q!("    leal            " "(%rax, %r14, 1), %eax"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    vpsrld          " "$7, %ymm4, %ymm6"),
        Q!("    andnl           " "%r10d, %r8d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r8d, %r14d"),
        Q!("    vpaddd          " "%ymm7, %ymm2, %ymm2"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    vpsrld          " "$3, %ymm4, %ymm7"),
        Q!("    rorxl           " "$22, %eax, %r12d"),
        Q!("    leal            " "(%r11, %r13, 1), %r11d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    vpslld          " "$14, %ymm4, %ymm5"),
        Q!("    rorxl           " "$13, %eax, %r14d"),
        Q!("    rorxl           " "$2, %eax, %r13d"),
        Q!("    leal            " "(%rdx, %r11, 1), %edx"),
        Q!("    vpxor           " "%ymm6, %ymm7, %ymm4"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    vpshufd         " "$250, %ymm1, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r11, %rdi, 1), %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    vpsrld          " "$11, %ymm6, %ymm6"),
        Q!("    addl            " "4 + 128 (%rsp), %r10d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    rorxl           " "$25, %edx, %r13d"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$11, %edx, %edi"),
        Q!("    leal            " "(%r11, %r14, 1), %r11d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    vpslld          " "$11, %ymm5, %ymm5"),
        Q!("    andnl           " "%r9d, %edx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %edx, %r14d"),
        Q!("    vpxor           " "%ymm6, %ymm4, %ymm4"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    rorxl           " "$22, %r11d, %r12d"),
        Q!("    leal            " "(%r10, %r13, 1), %r10d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$13, %r11d, %r14d"),
        Q!("    rorxl           " "$2, %r11d, %r13d"),
        Q!("    leal            " "(%rcx, %r10, 1), %ecx"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    vpaddd          " "%ymm4, %ymm2, %ymm2"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r10, %r15, 1), %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "8 + 128 (%rsp), %r9d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    rorxl           " "$25, %ecx, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %ecx, %r15d"),
        Q!("    leal            " "(%r10, %r14, 1), %r10d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%r8d, %ecx, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %ecx, %r14d"),
        Q!("    vpshufb         " "%ymm8, %ymm6, %ymm6"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    vpaddd          " "%ymm6, %ymm2, %ymm2"),
        Q!("    rorxl           " "$22, %r10d, %r12d"),
        Q!("    leal            " "(%r9, %r13, 1), %r9d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    vpshufd         " "$80, %ymm2, %ymm7"),
        Q!("    rorxl           " "$13, %r10d, %r14d"),
        Q!("    rorxl           " "$2, %r10d, %r13d"),
        Q!("    leal            " "(%rbx, %r9, 1), %ebx"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r9, %rdi, 1), %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "12 + 128 (%rsp), %r8d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    rorxl           " "$25, %ebx, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %ebx, %edi"),
        Q!("    leal            " "(%r9, %r14, 1), %r9d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%edx, %ebx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %ebx, %r14d"),
        Q!("    vpshufb         " "%ymm9, %ymm6, %ymm6"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    vpaddd          " "%ymm6, %ymm2, %ymm2"),
        Q!("    rorxl           " "$22, %r9d, %r12d"),
        Q!("    leal            " "(%r8, %r13, 1), %r8d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    vpaddd          " "64 (%rsi), %ymm2, %ymm6"),
        Q!("    rorxl           " "$13, %r9d, %r14d"),
        Q!("    rorxl           " "$2, %r9d, %r13d"),
        Q!("    leal            " "(%rax, %r8, 1), %eax"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r8, %r15, 1), %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    vmovdqa         " "%ymm6, 0 (%rsp)"),
        Q!("    vpalignr        " "$4, %ymm3, %ymm0, %ymm4"),
        Q!("    addl            " "32 + 128 (%rsp), %edx"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    rorxl           " "$25, %eax, %r13d"),
        Q!("    vpalignr        " "$4, %ymm1, %ymm2, %ymm7"),
        Q!("    rorxl           " "$11, %eax, %r15d"),
        Q!("    leal            " "(%r8, %r14, 1), %r8d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    vpsrld          " "$7, %ymm4, %ymm6"),
        Q!("    andnl           " "%ecx, %eax, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %eax, %r14d"),
        Q!("    vpaddd          " "%ymm7, %ymm3, %ymm3"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    vpsrld          " "$3, %ymm4, %ymm7"),
        Q!("    rorxl           " "$22, %r8d, %r12d"),
        Q!("    leal            " "(%rdx, %r13, 1), %edx"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    vpslld          " "$14, %ymm4, %ymm5"),
        Q!("    rorxl           " "$13, %r8d, %r14d"),
        Q!("    rorxl           " "$2, %r8d, %r13d"),
        Q!("    leal            " "(%r11, %rdx, 1), %r11d"),
        Q!("    vpxor           " "%ymm6, %ymm7, %ymm4"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    vpshufd         " "$250, %ymm2, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rdx, %rdi, 1), %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    vpsrld          " "$11, %ymm6, %ymm6"),
        Q!("    addl            " "36 + 128 (%rsp), %ecx"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    rorxl           " "$25, %r11d, %r13d"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$11, %r11d, %edi"),
        Q!("    leal            " "(%rdx, %r14, 1), %edx"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    vpslld          " "$11, %ymm5, %ymm5"),
        Q!("    andnl           " "%ebx, %r11d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r11d, %r14d"),
        Q!("    vpxor           " "%ymm6, %ymm4, %ymm4"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    rorxl           " "$22, %edx, %r12d"),
        Q!("    leal            " "(%rcx, %r13, 1), %ecx"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    vpxor           " "%ymm5, %ymm4, %ymm4"),
        Q!("    rorxl           " "$13, %edx, %r14d"),
        Q!("    rorxl           " "$2, %edx, %r13d"),
        Q!("    leal            " "(%r10, %rcx, 1), %r10d"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    vpaddd          " "%ymm4, %ymm3, %ymm3"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rcx, %r15, 1), %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "40 + 128 (%rsp), %ebx"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    rorxl           " "$25, %r10d, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %r10d, %r15d"),
        Q!("    leal            " "(%rcx, %r14, 1), %ecx"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%eax, %r10d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r10d, %r14d"),
        Q!("    vpshufb         " "%ymm8, %ymm6, %ymm6"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    vpaddd          " "%ymm6, %ymm3, %ymm3"),
        Q!("    rorxl           " "$22, %ecx, %r12d"),
        Q!("    leal            " "(%rbx, %r13, 1), %ebx"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    vpshufd         " "$80, %ymm3, %ymm7"),
        Q!("    rorxl           " "$13, %ecx, %r14d"),
        Q!("    rorxl           " "$2, %ecx, %r13d"),
        Q!("    leal            " "(%r9, %rbx, 1), %r9d"),
        Q!("    vpsrld          " "$10, %ymm7, %ymm6"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    vpsrlq          " "$17, %ymm7, %ymm7"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rbx, %rdi, 1), %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    addl            " "44 + 128 (%rsp), %eax"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    rorxl           " "$25, %r9d, %r13d"),
        Q!("    vpsrlq          " "$2, %ymm7, %ymm7"),
        Q!("    rorxl           " "$11, %r9d, %edi"),
        Q!("    leal            " "(%rbx, %r14, 1), %ebx"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    vpxor           " "%ymm7, %ymm6, %ymm6"),
        Q!("    andnl           " "%r11d, %r9d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r9d, %r14d"),
        Q!("    vpshufb         " "%ymm9, %ymm6, %ymm6"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    vpaddd          " "%ymm6, %ymm3, %ymm3"),
        Q!("    rorxl           " "$22, %ebx, %r12d"),
        Q!("    leal            " "(%rax, %r13, 1), %eax"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    vpaddd          " "96 (%rsi), %ymm3, %ymm6"),
        Q!("    rorxl           " "$13, %ebx, %r14d"),
        Q!("    rorxl           " "$2, %ebx, %r13d"),
        Q!("    leal            " "(%r8, %rax, 1), %r8d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rax, %r15, 1), %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    vmovdqa         " "%ymm6, 32 (%rsp)"),
        Q!("    leaq            " "128 (%rsi), %rsi"),
        Q!("    cmpb            " "$0, 3 (%rsi)"),
        Q!("    jne             " Label!(".Lavx2_00_47", 4, Before)),
        Q!("    addl            " "0 + 64 (%rsp), %r11d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    rorxl           " "$25, %r8d, %r13d"),
        Q!("    rorxl           " "$11, %r8d, %r15d"),
        Q!("    leal            " "(%rax, %r14, 1), %eax"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    andnl           " "%r10d, %r8d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r8d, %r14d"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    rorxl           " "$22, %eax, %r12d"),
        Q!("    leal            " "(%r11, %r13, 1), %r11d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    rorxl           " "$13, %eax, %r14d"),
        Q!("    rorxl           " "$2, %eax, %r13d"),
        Q!("    leal            " "(%rdx, %r11, 1), %edx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r11, %rdi, 1), %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    addl            " "4 + 64 (%rsp), %r10d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    rorxl           " "$25, %edx, %r13d"),
        Q!("    rorxl           " "$11, %edx, %edi"),
        Q!("    leal            " "(%r11, %r14, 1), %r11d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    andnl           " "%r9d, %edx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %edx, %r14d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    rorxl           " "$22, %r11d, %r12d"),
        Q!("    leal            " "(%r10, %r13, 1), %r10d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    rorxl           " "$13, %r11d, %r14d"),
        Q!("    rorxl           " "$2, %r11d, %r13d"),
        Q!("    leal            " "(%rcx, %r10, 1), %ecx"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r10, %r15, 1), %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    addl            " "8 + 64 (%rsp), %r9d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    rorxl           " "$25, %ecx, %r13d"),
        Q!("    rorxl           " "$11, %ecx, %r15d"),
        Q!("    leal            " "(%r10, %r14, 1), %r10d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    andnl           " "%r8d, %ecx, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %ecx, %r14d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    rorxl           " "$22, %r10d, %r12d"),
        Q!("    leal            " "(%r9, %r13, 1), %r9d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    rorxl           " "$13, %r10d, %r14d"),
        Q!("    rorxl           " "$2, %r10d, %r13d"),
        Q!("    leal            " "(%rbx, %r9, 1), %ebx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r9, %rdi, 1), %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    addl            " "12 + 64 (%rsp), %r8d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    rorxl           " "$25, %ebx, %r13d"),
        Q!("    rorxl           " "$11, %ebx, %edi"),
        Q!("    leal            " "(%r9, %r14, 1), %r9d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    andnl           " "%edx, %ebx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %ebx, %r14d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    rorxl           " "$22, %r9d, %r12d"),
        Q!("    leal            " "(%r8, %r13, 1), %r8d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    rorxl           " "$13, %r9d, %r14d"),
        Q!("    rorxl           " "$2, %r9d, %r13d"),
        Q!("    leal            " "(%rax, %r8, 1), %eax"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r8, %r15, 1), %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    addl            " "32 + 64 (%rsp), %edx"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    rorxl           " "$25, %eax, %r13d"),
        Q!("    rorxl           " "$11, %eax, %r15d"),
        Q!("    leal            " "(%r8, %r14, 1), %r8d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    andnl           " "%ecx, %eax, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %eax, %r14d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    rorxl           " "$22, %r8d, %r12d"),
        Q!("    leal            " "(%rdx, %r13, 1), %edx"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    rorxl           " "$13, %r8d, %r14d"),
        Q!("    rorxl           " "$2, %r8d, %r13d"),
        Q!("    leal            " "(%r11, %rdx, 1), %r11d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rdx, %rdi, 1), %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    addl            " "36 + 64 (%rsp), %ecx"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    rorxl           " "$25, %r11d, %r13d"),
        Q!("    rorxl           " "$11, %r11d, %edi"),
        Q!("    leal            " "(%rdx, %r14, 1), %edx"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    andnl           " "%ebx, %r11d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r11d, %r14d"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    rorxl           " "$22, %edx, %r12d"),
        Q!("    leal            " "(%rcx, %r13, 1), %ecx"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    rorxl           " "$13, %edx, %r14d"),
        Q!("    rorxl           " "$2, %edx, %r13d"),
        Q!("    leal            " "(%r10, %rcx, 1), %r10d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rcx, %r15, 1), %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    addl            " "40 + 64 (%rsp), %ebx"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    rorxl           " "$25, %r10d, %r13d"),
        Q!("    rorxl           " "$11, %r10d, %r15d"),
        Q!("    leal            " "(%rcx, %r14, 1), %ecx"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    andnl           " "%eax, %r10d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r10d, %r14d"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    rorxl           " "$22, %ecx, %r12d"),
        Q!("    leal            " "(%rbx, %r13, 1), %ebx"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    rorxl           " "$13, %ecx, %r14d"),
        Q!("    rorxl           " "$2, %ecx, %r13d"),
        Q!("    leal            " "(%r9, %rbx, 1), %r9d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rbx, %rdi, 1), %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    addl            " "44 + 64 (%rsp), %eax"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    rorxl           " "$25, %r9d, %r13d"),
        Q!("    rorxl           " "$11, %r9d, %edi"),
        Q!("    leal            " "(%rbx, %r14, 1), %ebx"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    andnl           " "%r11d, %r9d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r9d, %r14d"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    rorxl           " "$22, %ebx, %r12d"),
        Q!("    leal            " "(%rax, %r13, 1), %eax"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    rorxl           " "$13, %ebx, %r14d"),
        Q!("    rorxl           " "$2, %ebx, %r13d"),
        Q!("    leal            " "(%r8, %rax, 1), %r8d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rax, %r15, 1), %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    addl            " "0 (%rsp), %r11d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    rorxl           " "$25, %r8d, %r13d"),
        Q!("    rorxl           " "$11, %r8d, %r15d"),
        Q!("    leal            " "(%rax, %r14, 1), %eax"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    andnl           " "%r10d, %r8d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r8d, %r14d"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    rorxl           " "$22, %eax, %r12d"),
        Q!("    leal            " "(%r11, %r13, 1), %r11d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    rorxl           " "$13, %eax, %r14d"),
        Q!("    rorxl           " "$2, %eax, %r13d"),
        Q!("    leal            " "(%rdx, %r11, 1), %edx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r11, %rdi, 1), %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    addl            " "4 (%rsp), %r10d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    rorxl           " "$25, %edx, %r13d"),
        Q!("    rorxl           " "$11, %edx, %edi"),
        Q!("    leal            " "(%r11, %r14, 1), %r11d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    andnl           " "%r9d, %edx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %edx, %r14d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    rorxl           " "$22, %r11d, %r12d"),
        Q!("    leal            " "(%r10, %r13, 1), %r10d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    rorxl           " "$13, %r11d, %r14d"),
        Q!("    rorxl           " "$2, %r11d, %r13d"),
        Q!("    leal            " "(%rcx, %r10, 1), %ecx"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r10, %r15, 1), %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    addl            " "8 (%rsp), %r9d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    rorxl           " "$25, %ecx, %r13d"),
        Q!("    rorxl           " "$11, %ecx, %r15d"),
        Q!("    leal            " "(%r10, %r14, 1), %r10d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    andnl           " "%r8d, %ecx, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %ecx, %r14d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    rorxl           " "$22, %r10d, %r12d"),
        Q!("    leal            " "(%r9, %r13, 1), %r9d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    rorxl           " "$13, %r10d, %r14d"),
        Q!("    rorxl           " "$2, %r10d, %r13d"),
        Q!("    leal            " "(%rbx, %r9, 1), %ebx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r9, %rdi, 1), %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    addl            " "12 (%rsp), %r8d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    rorxl           " "$25, %ebx, %r13d"),
        Q!("    rorxl           " "$11, %ebx, %edi"),
        Q!("    leal            " "(%r9, %r14, 1), %r9d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    andnl           " "%edx, %ebx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %ebx, %r14d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    rorxl           " "$22, %r9d, %r12d"),
        Q!("    leal            " "(%r8, %r13, 1), %r8d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    rorxl           " "$13, %r9d, %r14d"),
        Q!("    rorxl           " "$2, %r9d, %r13d"),
        Q!("    leal            " "(%rax, %r8, 1), %eax"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r8, %r15, 1), %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    addl            " "32 (%rsp), %edx"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    rorxl           " "$25, %eax, %r13d"),
        Q!("    rorxl           " "$11, %eax, %r15d"),
        Q!("    leal            " "(%r8, %r14, 1), %r8d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    andnl           " "%ecx, %eax, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %eax, %r14d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    rorxl           " "$22, %r8d, %r12d"),
        Q!("    leal            " "(%rdx, %r13, 1), %edx"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    rorxl           " "$13, %r8d, %r14d"),
        Q!("    rorxl           " "$2, %r8d, %r13d"),
        Q!("    leal            " "(%r11, %rdx, 1), %r11d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rdx, %rdi, 1), %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    addl            " "36 (%rsp), %ecx"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    rorxl           " "$25, %r11d, %r13d"),
        Q!("    rorxl           " "$11, %r11d, %edi"),
        Q!("    leal            " "(%rdx, %r14, 1), %edx"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    andnl           " "%ebx, %r11d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r11d, %r14d"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    rorxl           " "$22, %edx, %r12d"),
        Q!("    leal            " "(%rcx, %r13, 1), %ecx"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    rorxl           " "$13, %edx, %r14d"),
        Q!("    rorxl           " "$2, %edx, %r13d"),
        Q!("    leal            " "(%r10, %rcx, 1), %r10d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rcx, %r15, 1), %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    addl            " "40 (%rsp), %ebx"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    rorxl           " "$25, %r10d, %r13d"),
        Q!("    rorxl           " "$11, %r10d, %r15d"),
        Q!("    leal            " "(%rcx, %r14, 1), %ecx"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    andnl           " "%eax, %r10d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r10d, %r14d"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    rorxl           " "$22, %ecx, %r12d"),
        Q!("    leal            " "(%rbx, %r13, 1), %ebx"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    rorxl           " "$13, %ecx, %r14d"),
        Q!("    rorxl           " "$2, %ecx, %r13d"),
        Q!("    leal            " "(%r9, %rbx, 1), %r9d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rbx, %rdi, 1), %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    addl            " "44 (%rsp), %eax"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    rorxl           " "$25, %r9d, %r13d"),
        Q!("    rorxl           " "$11, %r9d, %edi"),
        Q!("    leal            " "(%rbx, %r14, 1), %ebx"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    andnl           " "%r11d, %r9d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r9d, %r14d"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    rorxl           " "$22, %ebx, %r12d"),
        Q!("    leal            " "(%rax, %r13, 1), %eax"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    rorxl           " "$13, %ebx, %r14d"),
        Q!("    rorxl           " "$2, %ebx, %r13d"),
        Q!("    leal            " "(%r8, %rax, 1), %r8d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rax, %r15, 1), %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    addl            " "%r14d, %eax"),
        Q!("    movl            " "-56 (%rbp), %r12d"),
        Q!("    addl            " "0 (%rdi), %eax"),
        Q!("    addl            " "4 (%rdi), %ebx"),
        Q!("    addl            " "8 (%rdi), %ecx"),
        Q!("    addl            " "12 (%rdi), %edx"),
        Q!("    addl            " "16 (%rdi), %r8d"),
        Q!("    addl            " "20 (%rdi), %r9d"),
        Q!("    addl            " "24 (%rdi), %r10d"),
        Q!("    addl            " "28 (%rdi), %r11d"),
        Q!("    movl            " "%eax, 0 (%rdi)"),
        Q!("    movl            " "%ebx, 4 (%rdi)"),
        Q!("    movl            " "%ecx, 8 (%rdi)"),
        Q!("    movl            " "%edx, 12 (%rdi)"),
        Q!("    movl            " "%r8d, 16 (%rdi)"),
        Q!("    movl            " "%r9d, 20 (%rdi)"),
        Q!("    movl            " "%r10d, 24 (%rdi)"),
        Q!("    movl            " "%r11d, 28 (%rdi)"),
        Q!("    cmpl            " "-48 (%rbp), %r12d"),
        Q!("    je              " Label!(".Ldone_avx2", 5, After)),
        Q!("    leaq            " "448 (%rsp), %rsi"),
        Q!("    xorl            " "%r14d, %r14d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    jmp             " Label!(".Lower_avx2", 6, After)),
        Q!(Label!(".Lower_avx2", 6) ":"),
        Q!("    addl            " "0 + 16 (%rsi), %r11d"),
        Q!("    andl            " "%r8d, %r12d"),
        Q!("    rorxl           " "$25, %r8d, %r13d"),
        Q!("    rorxl           " "$11, %r8d, %r15d"),
        Q!("    leal            " "(%rax, %r14, 1), %eax"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    andnl           " "%r10d, %r8d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r8d, %r14d"),
        Q!("    leal            " "(%r11, %r12, 1), %r11d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%eax, %r15d"),
        Q!("    rorxl           " "$22, %eax, %r12d"),
        Q!("    leal            " "(%r11, %r13, 1), %r11d"),
        Q!("    xorl            " "%ebx, %r15d"),
        Q!("    rorxl           " "$13, %eax, %r14d"),
        Q!("    rorxl           " "$2, %eax, %r13d"),
        Q!("    leal            " "(%rdx, %r11, 1), %edx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ebx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r11, %rdi, 1), %r11d"),
        Q!("    movl            " "%r8d, %r12d"),
        Q!("    addl            " "4 + 16 (%rsi), %r10d"),
        Q!("    andl            " "%edx, %r12d"),
        Q!("    rorxl           " "$25, %edx, %r13d"),
        Q!("    rorxl           " "$11, %edx, %edi"),
        Q!("    leal            " "(%r11, %r14, 1), %r11d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    andnl           " "%r9d, %edx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %edx, %r14d"),
        Q!("    leal            " "(%r10, %r12, 1), %r10d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r11d, %edi"),
        Q!("    rorxl           " "$22, %r11d, %r12d"),
        Q!("    leal            " "(%r10, %r13, 1), %r10d"),
        Q!("    xorl            " "%eax, %edi"),
        Q!("    rorxl           " "$13, %r11d, %r14d"),
        Q!("    rorxl           " "$2, %r11d, %r13d"),
        Q!("    leal            " "(%rcx, %r10, 1), %ecx"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%eax, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r10, %r15, 1), %r10d"),
        Q!("    movl            " "%edx, %r12d"),
        Q!("    addl            " "8 + 16 (%rsi), %r9d"),
        Q!("    andl            " "%ecx, %r12d"),
        Q!("    rorxl           " "$25, %ecx, %r13d"),
        Q!("    rorxl           " "$11, %ecx, %r15d"),
        Q!("    leal            " "(%r10, %r14, 1), %r10d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    andnl           " "%r8d, %ecx, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %ecx, %r14d"),
        Q!("    leal            " "(%r9, %r12, 1), %r9d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r10d, %r15d"),
        Q!("    rorxl           " "$22, %r10d, %r12d"),
        Q!("    leal            " "(%r9, %r13, 1), %r9d"),
        Q!("    xorl            " "%r11d, %r15d"),
        Q!("    rorxl           " "$13, %r10d, %r14d"),
        Q!("    rorxl           " "$2, %r10d, %r13d"),
        Q!("    leal            " "(%rbx, %r9, 1), %ebx"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r11d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r9, %rdi, 1), %r9d"),
        Q!("    movl            " "%ecx, %r12d"),
        Q!("    addl            " "12 + 16 (%rsi), %r8d"),
        Q!("    andl            " "%ebx, %r12d"),
        Q!("    rorxl           " "$25, %ebx, %r13d"),
        Q!("    rorxl           " "$11, %ebx, %edi"),
        Q!("    leal            " "(%r9, %r14, 1), %r9d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    andnl           " "%edx, %ebx, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %ebx, %r14d"),
        Q!("    leal            " "(%r8, %r12, 1), %r8d"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r9d, %edi"),
        Q!("    rorxl           " "$22, %r9d, %r12d"),
        Q!("    leal            " "(%r8, %r13, 1), %r8d"),
        Q!("    xorl            " "%r10d, %edi"),
        Q!("    rorxl           " "$13, %r9d, %r14d"),
        Q!("    rorxl           " "$2, %r9d, %r13d"),
        Q!("    leal            " "(%rax, %r8, 1), %eax"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r10d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%r8, %r15, 1), %r8d"),
        Q!("    movl            " "%ebx, %r12d"),
        Q!("    addl            " "32 + 16 (%rsi), %edx"),
        Q!("    andl            " "%eax, %r12d"),
        Q!("    rorxl           " "$25, %eax, %r13d"),
        Q!("    rorxl           " "$11, %eax, %r15d"),
        Q!("    leal            " "(%r8, %r14, 1), %r8d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    andnl           " "%ecx, %eax, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %eax, %r14d"),
        Q!("    leal            " "(%rdx, %r12, 1), %edx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%r8d, %r15d"),
        Q!("    rorxl           " "$22, %r8d, %r12d"),
        Q!("    leal            " "(%rdx, %r13, 1), %edx"),
        Q!("    xorl            " "%r9d, %r15d"),
        Q!("    rorxl           " "$13, %r8d, %r14d"),
        Q!("    rorxl           " "$2, %r8d, %r13d"),
        Q!("    leal            " "(%r11, %rdx, 1), %r11d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r9d, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rdx, %rdi, 1), %edx"),
        Q!("    movl            " "%eax, %r12d"),
        Q!("    addl            " "36 + 16 (%rsi), %ecx"),
        Q!("    andl            " "%r11d, %r12d"),
        Q!("    rorxl           " "$25, %r11d, %r13d"),
        Q!("    rorxl           " "$11, %r11d, %edi"),
        Q!("    leal            " "(%rdx, %r14, 1), %edx"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    andnl           " "%ebx, %r11d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r11d, %r14d"),
        Q!("    leal            " "(%rcx, %r12, 1), %ecx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%edx, %edi"),
        Q!("    rorxl           " "$22, %edx, %r12d"),
        Q!("    leal            " "(%rcx, %r13, 1), %ecx"),
        Q!("    xorl            " "%r8d, %edi"),
        Q!("    rorxl           " "$13, %edx, %r14d"),
        Q!("    rorxl           " "$2, %edx, %r13d"),
        Q!("    leal            " "(%r10, %rcx, 1), %r10d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%r8d, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rcx, %r15, 1), %ecx"),
        Q!("    movl            " "%r11d, %r12d"),
        Q!("    addl            " "40 + 16 (%rsi), %ebx"),
        Q!("    andl            " "%r10d, %r12d"),
        Q!("    rorxl           " "$25, %r10d, %r13d"),
        Q!("    rorxl           " "$11, %r10d, %r15d"),
        Q!("    leal            " "(%rcx, %r14, 1), %ecx"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    andnl           " "%eax, %r10d, %r12d"),
        Q!("    xorl            " "%r15d, %r13d"),
        Q!("    rorxl           " "$6, %r10d, %r14d"),
        Q!("    leal            " "(%rbx, %r12, 1), %ebx"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ecx, %r15d"),
        Q!("    rorxl           " "$22, %ecx, %r12d"),
        Q!("    leal            " "(%rbx, %r13, 1), %ebx"),
        Q!("    xorl            " "%edx, %r15d"),
        Q!("    rorxl           " "$13, %ecx, %r14d"),
        Q!("    rorxl           " "$2, %ecx, %r13d"),
        Q!("    leal            " "(%r9, %rbx, 1), %r9d"),
        Q!("    andl            " "%r15d, %edi"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%edx, %edi"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rbx, %rdi, 1), %ebx"),
        Q!("    movl            " "%r10d, %r12d"),
        Q!("    addl            " "44 + 16 (%rsi), %eax"),
        Q!("    andl            " "%r9d, %r12d"),
        Q!("    rorxl           " "$25, %r9d, %r13d"),
        Q!("    rorxl           " "$11, %r9d, %edi"),
        Q!("    leal            " "(%rbx, %r14, 1), %ebx"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    andnl           " "%r11d, %r9d, %r12d"),
        Q!("    xorl            " "%edi, %r13d"),
        Q!("    rorxl           " "$6, %r9d, %r14d"),
        Q!("    leal            " "(%rax, %r12, 1), %eax"),
        Q!("    xorl            " "%r14d, %r13d"),
        Q!("    movl            " "%ebx, %edi"),
        Q!("    rorxl           " "$22, %ebx, %r12d"),
        Q!("    leal            " "(%rax, %r13, 1), %eax"),
        Q!("    xorl            " "%ecx, %edi"),
        Q!("    rorxl           " "$13, %ebx, %r14d"),
        Q!("    rorxl           " "$2, %ebx, %r13d"),
        Q!("    leal            " "(%r8, %rax, 1), %r8d"),
        Q!("    andl            " "%edi, %r15d"),
        Q!("    xorl            " "%r12d, %r14d"),
        Q!("    xorl            " "%ecx, %r15d"),
        Q!("    xorl            " "%r13d, %r14d"),
        Q!("    leal            " "(%rax, %r15, 1), %eax"),
        Q!("    movl            " "%r9d, %r12d"),
        Q!("    leaq            " "-64 (%rsi), %rsi"),
        Q!("    cmpq            " "%rsp, %rsi"),
        Q!("    jae             " Label!(".Lower_avx2", 6, Before)),
        Q!("    movq            " "-64 (%rbp), %rdi"),
        Q!("    addl            " "%r14d, %eax"),
        Q!("    movq            " "-56 (%rbp), %rsi"),
        Q!("    leaq            " "448 (%rsp), %rsp"),
        Q!("    addl            " "0 (%rdi), %eax"),
        Q!("    addl            " "4 (%rdi), %ebx"),
        Q!("    addl            " "8 (%rdi), %ecx"),
        Q!("    addl            " "12 (%rdi), %edx"),
        Q!("    addl            " "16 (%rdi), %r8d"),
        Q!("    addl            " "20 (%rdi), %r9d"),
        Q!("    leaq            " "128 (%rsi), %rsi"),
        Q!("    addl            " "24 (%rdi), %r10d"),
        Q!("    movq            " "%rsi, %r12"),
        Q!("    addl            " "28 (%rdi), %r11d"),
        Q!("    cmpq            " "-48 (%rbp), %rsi"),
        Q!("    movl            " "%eax, 0 (%rdi)"),
        Q!("    cmoveq          " "%rsp, %r12"),
        Q!("    movl            " "%ebx, 4 (%rdi)"),
        Q!("    movl            " "%ecx, 8 (%rdi)"),
        Q!("    movl            " "%edx, 12 (%rdi)"),
        Q!("    movl            " "%r8d, 16 (%rdi)"),
        Q!("    movl            " "%r9d, 20 (%rdi)"),
        Q!("    movl            " "%r10d, 24 (%rdi)"),
        Q!("    movl            " "%r11d, 28 (%rdi)"),
        Q!("    jbe             " Label!(".Loop_avx2", 3, Before)),
        Q!(Label!(".Ldone_avx2", 5) ":"),
        Q!("    vzeroupper      " ),
        Q!("    movq            " "-40 (%rbp), %r15"),
        Q!("    movq            " "-32 (%rbp), %r14"),
        Q!("    movq            " "-24 (%rbp), %r13"),
        Q!("    movq            " "-16 (%rbp), %r12"),
        Q!("    movq            " "-8 (%rbp), %rbx"),
        Q!("    movq            " "%rbp, %rsp"),
        Q!("    popq            " "%rbp"),
        inout("rdi") state.as_mut_ptr() => _,
        inout("rsi") blocks.as_ptr() => _,
        inout("rdx") blocks.len() / 64 => _,
        K256 = sym K256,
        // clobbers
        out("r10") _,
        out("r11") _,
        out("r12") _,
        out("r13") _,
        out("r14") _,
        out("r15") _,
        out("r8") _,
        out("r9") _,
        out("rax") _,
        out("rcx") _,
        out("zmm0") _,
        out("zmm1") _,
        out("zmm2") _,
        out("zmm3") _,
        out("zmm4") _,
        out("zmm5") _,
        out("zmm6") _,
        out("zmm7") _,
        out("zmm8") _,
        out("zmm9") _,
        options(att_syntax),
            )
    };
}
#[allow(dead_code)]
#[repr(align(64))]
struct B64Alignedu32Array152([u32; 152]);

static K256: B64Alignedu32Array152 = B64Alignedu32Array152([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2,
    0x00010203, 0x04050607, 0x08090a0b, 0x0c0d0e0f, 0x00010203, 0x04050607, 0x08090a0b, 0x0c0d0e0f,
    0x03020100, 0x0b0a0908, 0xffffffff, 0xffffffff, 0x03020100, 0x0b0a0908, 0xffffffff, 0xffffffff,
    0xffffffff, 0xffffffff, 0x03020100, 0x0b0a0908, 0xffffffff, 0xffffffff, 0x03020100, 0x0b0a0908,
]);
